{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required dependencies\n",
    "# 1. NLTK\n",
    "# 2. Gensim for word2vec\n",
    "# 3. Keras with tensorflow/theano backend\n",
    "\n",
    "#=======================\n",
    "import json\n",
    "import codecs\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.layers import Reshape, Concatenate, Activation, LeakyReLU, Lambda, Bidirectional\n",
    "from gensim.test.utils import common_texts, get_tmpfile #10-11\n",
    "import gc\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from math import exp, log, e\n",
    "import tensorflow as tf\n",
    "from keras import metrics\n",
    "from IPython.display import Image\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "#========================\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "import json, re, nltk, string\n",
    "from nltk.corpus import wordnet\n",
    "from gensim.models import Word2Vec\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Input, merge, Masking, TimeDistributed\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.utils import np_utils, plot_model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report, confusion_matrix, mean_squared_error\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclipse = '/data/projects/eclipse.json'\n",
    "chrome = '/data/projects/chromium.json'\n",
    "firefox = '/data/prjects/firefox.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================================================\n",
    "# Initializing Hyper parameter\n",
    "#========================================================================================\n",
    "#1. Word2vec parameters\n",
    "min_word_frequency_word2vec = 30\n",
    "embed_size_word2vec = 200\n",
    "context_window_word2vec = 5\n",
    "combined_word2vec = True\n",
    "\n",
    "#2. Classifier hyperparameters\n",
    "numCV = 10\n",
    "max_sentence_len = 150\n",
    "min_sentence_length = 15\n",
    "max_his_len = 10\n",
    "max_activity_len = 10\n",
    "min_activity_len = 4\n",
    "batch_size = 32\n",
    "label_num=100\n",
    "class_std = 3 # 1=52%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start 2014-03-06 19:00:33\n",
      "30428\n",
      "100001\n",
      "end 2015-11-05 19:54:33\n"
     ]
    }
   ],
   "source": [
    "#==============================================================================\n",
    "# Preprocess 3 (ACTIVITY-BASED -> DATE-BASED)\n",
    "#==============================================================================\n",
    "path = eclipse\n",
    "data_name = {eclipse:'eclipse', chrome:'chrome', firefox:'firefox'}\n",
    "\n",
    "with_sys=False\n",
    "\n",
    "word2vec_train = True\n",
    "if word2vec_train:\n",
    "    all_data_word2vec = []\n",
    "accumulate =False\n",
    "cut_activity_len = True\n",
    "max_activity_len = 10\n",
    "noise_day = 3 \n",
    "limit_day = 100\n",
    "recentday = 3 # all_recentday\n",
    "\n",
    "stop_words = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'had', 'having', 'doing', 'a', 'an', 'the', 'and', 'or', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'between', 'into', 'through', 'during', 'before', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'too', 'very', 's', 't', 'd', 'll', 'm', 'o', 're', 've', 'y',  'ma']\n",
    "stop_words += list(string.ascii_lowercase)\n",
    "stop_words = set(stop_words)\n",
    "\n",
    "with open(path, encoding='utf-8') as data_file:\n",
    "    data = json.loads(data_file.read(), strict=False)\n",
    "    \n",
    "all_data = []\n",
    "all_history = []\n",
    "all_time = []\n",
    "#all_stream = []\n",
    "all_bugid = []\n",
    "all_total =[]\n",
    "\n",
    "all_workday = []\n",
    "all_recentday = []\n",
    "all_openday = []\n",
    "all_activitycnt = []\n",
    "all_cc = []\n",
    "all_writer = []\n",
    "all_commcnt = []\n",
    "all_hiscnt = []\n",
    "all_wordcnt = []\n",
    "\n",
    "start=0\n",
    "for item in data:\n",
    "    # 'except' condition\n",
    "    if path==eclipse and item['activity']!=[] and int(item['activity'][0][1].split('-')[0])<2013:\n",
    "        continue\n",
    "    if len(all_time)>=100000: break\n",
    "    if len(item['days']) == 0 or item['days'][0] >= limit_day or item['days'][-1]>noise_day:\n",
    "        continue\n",
    "        \n",
    "    # title\n",
    "    current_title = item['title'].replace('\\r', ' ')\n",
    "    current_title= re.sub(r'(\\w+)0x\\w+', '', current_title)\n",
    "    current_title = current_title.lower()\n",
    "    current_title = re.sub(r\"[!#$%&'()*+,./:;<=>?@\\^_`{|}~-]\", ' ', current_title)\n",
    "    current_title_tokens = nltk.word_tokenize(current_title)\n",
    "    current_title_filter = [word.strip(string.punctuation) for word in current_title_tokens]\n",
    "    \n",
    "    unique_date = [e[1].split(\" \")[0] for e in item['activity']]\n",
    "    unique_date = sorted(list(set(unique_date)))\n",
    "    if cut_activity_len and len(unique_date)>max_activity_len:\n",
    "        continue\n",
    "    \n",
    "    curr_activityCnt = 0\n",
    "    curr_workday = 0\n",
    "    #curr_stream = [0]*limit_day\n",
    "\n",
    "    curr_data_list = []\n",
    "    curr_history_list = []\n",
    "    for j,date in enumerate(unique_date):\n",
    "        curr_desc = \" \"\n",
    "        curr_his = \" \"\n",
    "        curr_workday +=1\n",
    "        this_activityCnt = 0\n",
    "        total_act = 0\n",
    "        comm_cnt = 0\n",
    "        his_cnt = 0 \n",
    "        tmp_cc = []\n",
    "        for idx, x in enumerate(item['activity']):\n",
    "            if x[1].split(' ')[0] > date:\n",
    "                break   \n",
    "            if not accumulate:\n",
    "                if x[1].split(' ')[0] < date:\n",
    "                    continue  \n",
    "            if x[2]!=\"\":\n",
    "                total_act+=1\n",
    "                comm_cnt +=1\n",
    "            if x[3]!=\"\":\n",
    "                total_act+=1\n",
    "                his_cnt +=1\n",
    "          \n",
    "            aft_x0 = re.sub(r'\\b(Comment)(\\s+)(\\d+)', r'\\1\\3', x[0])\n",
    "            if aft_x0.split()[0]=='Reported' or 'Description' in x[0]:\n",
    "                if aft_x0.split()[0]=='Reported':\n",
    "                    reporter = aft_x0.split()[2]\n",
    "                else:\n",
    "                    reporter = x[0].split()[0]\n",
    "    \n",
    "            if path==firefox:\n",
    "                cc = x[0].split()[0].strip(', ')\n",
    "            elif path ==chrome:\n",
    "                cc = aft_x0.split()[2].strip()\n",
    "            elif path==eclipse:\n",
    "                cc= x[0].split()[0]\n",
    "            tmp_cc.append(cc)\n",
    "            curr_desc += aft_x0+' '+x[2]+' '      \n",
    "            if with_sys:\n",
    "                aft_x3 = x[3].replace(':',' : ').replace('>', ' > ')\n",
    "                current_desc += aft_x3 + ' '\n",
    "            curr_his += x[3].replace(':',' : ').replace('>', ' > ') + ' '\n",
    "            curr_time = item['days'][idx]\n",
    "            curr_commentDate = item['commentDate'][idx]\n",
    "            curr_activityCnt+=1\n",
    "            this_activityCnt+=1\n",
    "        curr_active = [0]*recentday\n",
    "        for idx, x in enumerate(item['activity']):\n",
    "            for p in range(recentday,0,-1):\n",
    "                if item['days'][idx]-curr_time==p:\n",
    "                    curr_active[-p] = 1\n",
    "        \n",
    "        curr_desc = curr_desc.split()\n",
    "        curr_desc = [x for x in curr_desc if len(x)<100]\n",
    "        curr_desc = \" \".join(curr_desc)\n",
    "        curr_desc = curr_desc.replace('\\r', ' ')\n",
    "        curr_desc = re.sub(r\"(\\w+[\\w\\.]*)@(\\w+[\\w\\.]*)\\.([A-Za-z]+)\", r'\\1', curr_desc)\n",
    "        curr_desc = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', curr_desc)\n",
    "        curr_desc = re.sub(r'(\\w*)0x\\w+', ' ', curr_desc)\n",
    "        #curr_desc = re.sub(r'[^(A-Za-z0-9\\s)]+', ' ', curr_desc) # Solaris-specific >> solaris, specific\n",
    "        #print(5,curr_desc)\n",
    "        curr_desc = re.sub(r\"(\\s+)\\d+\", \" \", curr_desc)\n",
    "        curr_desc = curr_desc.lower()\n",
    "        curr_desc_tokens = nltk.word_tokenize(curr_desc) #word_tokenize\n",
    "        curr_desc_filter = [word.strip(string.punctuation) for word in curr_desc_tokens]\n",
    "        curr_data = (current_title_filter + curr_desc_filter) if j==0 else curr_desc_filter\n",
    "        curr_data = list(filter(None, curr_data))\n",
    "        curr_data = [w for w in curr_data if not w in stop_words]\n",
    "        \n",
    "        curr_his = curr_his.replace('✿','')\n",
    "        curr_his = re.sub(r\"(\\w+[\\w\\.]*)@(\\w+[\\w\\.]*)\\.([A-Za-z]+)\", r'\\1', curr_his) # mail-address\n",
    "        curr_his = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', curr_his)\n",
    "        #curr_his = re.sub(r'Attachment(\\s+)[#][0-9]+(\\s+)-', '', curr_his)\n",
    "        curr_his = curr_his.lower()\n",
    "        curr_his_tokens = nltk.word_tokenize(curr_his)\n",
    "        curr_his_filter = [word.strip(string.punctuation) for word in curr_his_tokens]\n",
    "        curr_history = list(filter(None, curr_his_filter))\n",
    "        curr_history = [w for w in curr_history if not w in stop_words]\n",
    "        \n",
    "        if word2vec_train and (curr_data+curr_history)!=[]:\n",
    "            all_data_word2vec.append(curr_data+curr_history)\n",
    "\n",
    "        #curr_stream[curr_commentDate] = this_activityCnt\n",
    "        #for x in range(curr_commentDate):\n",
    "        #    if curr_stream[x]== 0:\n",
    "        #        curr_stream[x] = -1\n",
    "        curr_data_list.append(curr_data)\n",
    "        curr_history_list.append(curr_history)\n",
    "        all_time.append(curr_time)\n",
    "        #all_stream.append(list(curr_stream))\n",
    "        all_bugid.append(item['reportNum'])\n",
    "        all_total.append(item['days'][0])\n",
    "\n",
    "        all_commcnt.append(comm_cnt)\n",
    "        all_hiscnt.append(his_cnt)\n",
    "        all_wordcnt.append(len(curr_history)+len(curr_data))\n",
    "        all_workday.append(curr_workday)\n",
    "        all_recentday.append(curr_active)\n",
    "        all_openday.append(curr_commentDate)\n",
    "        all_activitycnt.append(total_act)\n",
    "        all_cc.append(len(set(tmp_cc)))\n",
    "\n",
    "        min_writer = 0\n",
    "        if path == firefox:\n",
    "            tmp_writer = [0,0,0]\n",
    "            if 'reporter' in curr_data:\n",
    "                tmp_writer[0]=1\n",
    "                min_writer+=1\n",
    "            if 'assignee' in curr_data:\n",
    "                tmp_writer[1]=1\n",
    "                min_writer+=1\n",
    "            if len(tmp_cc)>min_writer:\n",
    "                tmp_writer[2]=1\n",
    "        elif path==chrome or path ==eclipse:\n",
    "            tmp_writer = [0,0]\n",
    "            if reporter in tmp_cc:\n",
    "                tmp_writer[0]=1\n",
    "                min_writer+=1\n",
    "            if len(tmp_cc)>min_writer:\n",
    "                tmp_writer[1]=1\n",
    "        all_writer.append(tmp_writer)\n",
    "\n",
    "        if start==0:\n",
    "            start = item['activity'][0][1]\n",
    "            print('start', start)\n",
    "        end = item['activity'][0][1]\n",
    "\n",
    "    all_data.append(curr_data_list)\n",
    "    all_history.append(curr_history_list)\n",
    "\n",
    "del data\n",
    "gc.collect()\n",
    "print(len(all_data))\n",
    "print(len(all_time))\n",
    "print('end', end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27696\n"
     ]
    }
   ],
   "source": [
    "# Load Word2vec\n",
    "\n",
    "if combined_word2vec:\n",
    "    if path == chrome:\n",
    "        wordvec_path = '/data/word2vec/chrome_combined200.model'\n",
    "    elif path ==eclipse:\n",
    "        wordvec_path = '/data/word2vec/eclipse_combined200.model'\n",
    "    elif path ==firefox:\n",
    "        wordvec_path = '/data/word2vec/firefox_combined200.model'\n",
    "    wordvec_model = Word2Vec.load(wordvec_path)\n",
    "    vocabulary = wordvec_model.wv.vocab\n",
    "else: \n",
    "    wordvec_path_1 = '/data/word2vec/newProject_all_data_word2vec.model'\n",
    "    wordvec_path_2 = '/data/word2vec/newProject_all_history_word2vec.model'\n",
    "    wordvec_model_1 = Word2Vec.load(wordvec_path_1)\n",
    "    wordvec_model_2 = Word2Vec.load(wordvec_path_2)\n",
    "    vocabulary_1 = wordvec_model_1.wv.vocab\n",
    "    vocabulary_2 = wordvec_model_2.wv.vocab\n",
    "\n",
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= d_size ============= 1\n",
      "class 1 비율 36.31463685363146\n",
      "Total length:  30428\n",
      "emb_std: 7\n",
      "seq_std: 5\n",
      "train_balancing False\n",
      "CV 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:258: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:271: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:382: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"ou...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:434: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"mi...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M3-RNN *******************\n",
      "\n",
      "\n",
      "******************* M5- seqence RNN *******************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:475: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ba...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:529: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ti...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_39 (InputLayer)        (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "masking_29 (Masking)         (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "forwards_1 (LSTM)            (None, 10, 256)           467968    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 256)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (None, 10, 2)             514       \n",
      "=================================================================\n",
      "Total params: 468,482\n",
      "Trainable params: 468,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 14106 samples, validate on 2490 samples\n",
      "Epoch 1/20\n",
      "14106/14106 [==============================] - 24s 2ms/step - loss: 0.4352 - acc: 0.7896 - val_loss: 0.4233 - val_acc: 0.7966\n",
      "Epoch 2/20\n",
      "14106/14106 [==============================] - 17s 1ms/step - loss: 0.4060 - acc: 0.8076 - val_loss: 0.4136 - val_acc: 0.8004\n",
      "Epoch 3/20\n",
      "14106/14106 [==============================] - 17s 1ms/step - loss: 0.3960 - acc: 0.8131 - val_loss: 0.4099 - val_acc: 0.8024\n",
      "Epoch 4/20\n",
      "14106/14106 [==============================] - 17s 1ms/step - loss: 0.3888 - acc: 0.8161 - val_loss: 0.4116 - val_acc: 0.8006\n",
      " ********* seq5-M5 Learning time: 76sec ********* \n",
      "\n",
      "Train_result\n",
      "\n",
      "{'val_loss': [0.42326300292608726, 0.41356918716047664, 0.4099339674275563, 0.4115677466114841], 'val_acc': [0.7965949612448971, 0.8003902778568038, 0.8023639754119168, 0.8006346741833361], 'loss': [0.4351558535298134, 0.4059778681194192, 0.39600301094381724, 0.3888441119636185], 'acc': [0.7895850383878752, 0.8076411350372074, 0.8130988932646337, 0.816111806190117]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:711: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:724: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M5 -sequence RNN *******************\n",
      "len(y_test_activity) 9251\n",
      "predictY [[0 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 0 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 1 1 1 1]\n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 0 1 1 1 1 1 1 1]]\n",
      "len(predictY) 9251\n",
      "Total test accuracy : 68.40\n",
      "\n",
      "Confusion Matrix\n",
      "[[1523 1837]\n",
      " [1086 4805]]\n",
      "\n",
      "f1_score: 76.68\n",
      "precision_score: 72.34\n",
      "recall_score: 81.57\n",
      "Predict 0: 28.20\n",
      "Predict 1: 71.80\n",
      "\n",
      "72.34 81.57 76.68 68.40\n",
      "\n",
      "\n",
      "Total length:  30428\n",
      "emb_std: 7\n",
      "seq_std: 5\n",
      "train_balancing False\n",
      "CV 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:258: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:271: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:382: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"ou...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:434: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"mi...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M3-RNN *******************\n",
      "\n",
      "\n",
      "******************* M5- seqence RNN *******************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:475: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ba...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:529: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ti...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_44 (InputLayer)        (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "masking_33 (Masking)         (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "forwards_1 (LSTM)            (None, 10, 256)           467968    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10, 256)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, 10, 2)             514       \n",
      "=================================================================\n",
      "Total params: 468,482\n",
      "Trainable params: 468,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16457 samples, validate on 2905 samples\n",
      "Epoch 1/20\n",
      "16457/16457 [==============================] - 28s 2ms/step - loss: 0.4670 - acc: 0.7705 - val_loss: 0.4497 - val_acc: 0.7831\n",
      "Epoch 2/20\n",
      "16457/16457 [==============================] - 20s 1ms/step - loss: 0.4488 - acc: 0.7825 - val_loss: 0.4470 - val_acc: 0.7791\n",
      "Epoch 3/20\n",
      "16457/16457 [==============================] - 20s 1ms/step - loss: 0.4424 - acc: 0.7852 - val_loss: 0.4411 - val_acc: 0.7874\n",
      "Epoch 4/20\n",
      "16457/16457 [==============================] - 20s 1ms/step - loss: 0.4378 - acc: 0.7870 - val_loss: 0.4424 - val_acc: 0.7862\n",
      " ********* seq5-M5 Learning time: 89sec ********* \n",
      "\n",
      "Train_result\n",
      "\n",
      "{'val_loss': [0.4496804495276354, 0.4470335326075759, 0.4411072931888797, 0.44242173925734635], 'val_acc': [0.7830951906317483, 0.7790794453809676, 0.787437435579382, 0.78619237586266], 'loss': [0.4669833782540352, 0.44875185355972375, 0.4423969069095923, 0.4377748424335232], 'acc': [0.7704870573963075, 0.7824722606616981, 0.7851783002886831, 0.7869762260974551]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:711: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:724: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M5 -sequence RNN *******************\n",
      "len(y_test_activity) 8929\n",
      "predictY [[0 1 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 1 0 1 1 1 1]\n",
      " [0 0 0 0 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 0 0 0 0 0 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]]\n",
      "len(predictY) 8929\n",
      "Total test accuracy : 68.44\n",
      "\n",
      "Confusion Matrix\n",
      "[[1624 1545]\n",
      " [1273 4487]]\n",
      "\n",
      "f1_score: 76.10\n",
      "precision_score: 74.39\n",
      "recall_score: 77.90\n",
      "Predict 0: 32.44\n",
      "Predict 1: 67.56\n",
      "\n",
      "74.39 77.90 76.10 68.44\n",
      "\n",
      "\n",
      "Total length:  30428\n",
      "emb_std: 7\n",
      "seq_std: 5\n",
      "train_balancing False\n",
      "CV 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:258: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:271: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:382: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"ou...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:434: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"mi...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M3-RNN *******************\n",
      "\n",
      "\n",
      "******************* M5- seqence RNN *******************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:475: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ba...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:529: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ti...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_49 (InputLayer)        (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "masking_37 (Masking)         (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "forwards_1 (LSTM)            (None, 10, 256)           467968    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10, 256)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_9 (TimeDist (None, 10, 2)             514       \n",
      "=================================================================\n",
      "Total params: 468,482\n",
      "Trainable params: 468,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 18808 samples, validate on 3320 samples\n",
      "Epoch 1/20\n",
      "18808/18808 [==============================] - 32s 2ms/step - loss: 0.4166 - acc: 0.8026 - val_loss: 0.4084 - val_acc: 0.8046\n",
      "Epoch 2/20\n",
      "18808/18808 [==============================] - 23s 1ms/step - loss: 0.3993 - acc: 0.8112 - val_loss: 0.4011 - val_acc: 0.8070\n",
      "Epoch 3/20\n",
      "18808/18808 [==============================] - 23s 1ms/step - loss: 0.3927 - acc: 0.8156 - val_loss: 0.4018 - val_acc: 0.8062\n",
      " ********* seq5-M5 Learning time: 78sec ********* \n",
      "\n",
      "Train_result\n",
      "\n",
      "{'val_loss': [0.4084473856242306, 0.40110123739185105, 0.40183131903050895], 'val_acc': [0.8045779485300363, 0.8069987353072109, 0.8061615793101758], 'loss': [0.41663810812326657, 0.399285490312053, 0.3927247203293885], 'acc': [0.8025833557180423, 0.8112166162147668, 0.8156012708154043]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:711: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:724: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M5 -sequence RNN *******************\n",
      "len(y_test_activity) 8889\n",
      "predictY [[1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 0 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [0 1 0 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 0 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]]\n",
      "len(predictY) 8889\n",
      "Total test accuracy : 67.70\n",
      "\n",
      "Confusion Matrix\n",
      "[[1447 1671]\n",
      " [1200 4571]]\n",
      "\n",
      "f1_score: 76.10\n",
      "precision_score: 73.23\n",
      "recall_score: 79.21\n",
      "Predict 0: 29.78\n",
      "Predict 1: 70.22\n",
      "\n",
      "73.23 79.21 76.10 67.70\n",
      "\n",
      "\n",
      "Total length:  30428\n",
      "emb_std: 7\n",
      "seq_std: 5\n",
      "train_balancing False\n",
      "CV 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:258: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:271: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:382: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"ou...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:434: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"mi...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M3-RNN *******************\n",
      "\n",
      "\n",
      "******************* M5- seqence RNN *******************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:475: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ba...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:529: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ti...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_54 (InputLayer)        (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "masking_41 (Masking)         (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "forwards_1 (LSTM)            (None, 10, 256)           467968    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 10, 256)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_10 (TimeDis (None, 10, 2)             514       \n",
      "=================================================================\n",
      "Total params: 468,482\n",
      "Trainable params: 468,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 21159 samples, validate on 3735 samples\n",
      "Epoch 1/20\n",
      "21159/21159 [==============================] - 36s 2ms/step - loss: 0.5280 - acc: 0.7243 - val_loss: 0.5359 - val_acc: 0.7196\n",
      "Epoch 2/20\n",
      "21159/21159 [==============================] - 27s 1ms/step - loss: 0.5142 - acc: 0.7344 - val_loss: 0.5284 - val_acc: 0.7272\n",
      "Epoch 3/20\n",
      "21159/21159 [==============================] - 22s 1ms/step - loss: 0.5099 - acc: 0.7364 - val_loss: 0.5236 - val_acc: 0.7284\n",
      "Epoch 4/20\n",
      "21159/21159 [==============================] - 22s 1ms/step - loss: 0.5064 - acc: 0.7392 - val_loss: 0.5251 - val_acc: 0.7290\n",
      " ********* seq5-M5 Learning time: 107sec ********* \n",
      "\n",
      "Train_result\n",
      "\n",
      "{'val_loss': [0.5359245658878342, 0.5284194758139461, 0.5235522634134075, 0.5251304230217634], 'val_acc': [0.7196359834358236, 0.7272480632725808, 0.7283910716553449, 0.7290061091483039], 'loss': [0.527996701657634, 0.5142220508157038, 0.5098557811760543, 0.5063627062904074], 'acc': [0.7242758457943163, 0.7344389442764488, 0.7363909656144342, 0.7392216862766373]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:711: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:724: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M5 -sequence RNN *******************\n",
      "len(y_test_activity) 9045\n",
      "predictY [[1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 1 1 1 1 1 1]\n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 0 0 0 0 0 0 0 0]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]]\n",
      "len(predictY) 9045\n",
      "Total test accuracy : 68.92\n",
      "\n",
      "Confusion Matrix\n",
      "[[1547 1814]\n",
      " [ 997 4687]]\n",
      "\n",
      "f1_score: 76.93\n",
      "precision_score: 72.10\n",
      "recall_score: 82.46\n",
      "Predict 0: 28.13\n",
      "Predict 1: 71.87\n",
      "\n",
      "72.10 82.46 76.93 68.92\n",
      "\n",
      "\n",
      "Total length:  30428\n",
      "emb_std: 7\n",
      "seq_std: 5\n",
      "train_balancing False\n",
      "CV 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:258: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:271: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:382: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"ou...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:434: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"mi...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M3-RNN *******************\n",
      "\n",
      "\n",
      "******************* M5- seqence RNN *******************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:475: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ba...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:529: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ti...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_59 (InputLayer)        (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "masking_45 (Masking)         (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "forwards_1 (LSTM)            (None, 10, 256)           467968    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 10, 256)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_11 (TimeDis (None, 10, 2)             514       \n",
      "=================================================================\n",
      "Total params: 468,482\n",
      "Trainable params: 468,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 23511 samples, validate on 4149 samples\n",
      "Epoch 1/20\n",
      "23511/23511 [==============================] - 34s 1ms/step - loss: 0.4231 - acc: 0.7984 - val_loss: 0.4049 - val_acc: 0.8049\n",
      "Epoch 2/20\n",
      "23511/23511 [==============================] - 29s 1ms/step - loss: 0.4075 - acc: 0.8074 - val_loss: 0.4047 - val_acc: 0.8067\n",
      "Epoch 3/20\n",
      "23511/23511 [==============================] - 29s 1ms/step - loss: 0.4022 - acc: 0.8094 - val_loss: 0.4002 - val_acc: 0.8085\n",
      "Epoch 4/20\n",
      "23511/23511 [==============================] - 29s 1ms/step - loss: 0.3993 - acc: 0.8107 - val_loss: 0.4016 - val_acc: 0.8085\n",
      " ********* seq5-M5 Learning time: 122sec ********* \n",
      "\n",
      "Train_result\n",
      "\n",
      "{'val_loss': [0.40491434806052334, 0.4046592604513483, 0.4002194698099976, 0.40159015309009016], 'val_acc': [0.8048979456265537, 0.8067379755466982, 0.8085282625391214, 0.808460262991716], 'loss': [0.4231148944579578, 0.40745310430412957, 0.40216762930399447, 0.39934086105615735], 'acc': [0.7983808525441876, 0.8074085900923582, 0.8094004062695422, 0.8106504810403506]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:711: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:724: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M5 -sequence RNN *******************\n",
      "len(y_test_activity) 9173\n",
      "predictY [[0 0 0 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]]\n",
      "len(predictY) 9173\n",
      "Total test accuracy : 68.01\n",
      "\n",
      "Confusion Matrix\n",
      "[[1730 1646]\n",
      " [1288 4509]]\n",
      "\n",
      "f1_score: 75.45\n",
      "precision_score: 73.26\n",
      "recall_score: 77.78\n",
      "Predict 0: 32.90\n",
      "Predict 1: 67.10\n",
      "\n",
      "73.26 77.78 75.45 68.01\n",
      "\n",
      "\n",
      "****************** 5 M5_runT, average : [76.95128297805786, 89.23302555084229, 78.33781147003174, 107.9632511138916, 122.31707167625427] 94.96048855781555 ******************\n",
      "\n",
      "\n",
      "class 1 비율 40.57059429405706\n",
      "Total length:  30428\n",
      "emb_std: 7\n",
      "seq_std: 4\n",
      "train_balancing False\n",
      "CV 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:258: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:271: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:382: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"ou...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:434: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"mi...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M3-RNN *******************\n",
      "\n",
      "\n",
      "******************* M5- seqence RNN *******************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:475: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ba...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:529: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ti...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_64 (InputLayer)        (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "masking_49 (Masking)         (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "forwards_1 (LSTM)            (None, 10, 256)           467968    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 10, 256)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_12 (TimeDis (None, 10, 2)             514       \n",
      "=================================================================\n",
      "Total params: 468,482\n",
      "Trainable params: 468,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 14106 samples, validate on 2490 samples\n",
      "Epoch 1/20\n",
      "14106/14106 [==============================] - 29s 2ms/step - loss: 0.4389 - acc: 0.7891 - val_loss: 0.4045 - val_acc: 0.8127\n",
      "Epoch 2/20\n",
      "14106/14106 [==============================] - 18s 1ms/step - loss: 0.4096 - acc: 0.8066 - val_loss: 0.3937 - val_acc: 0.8187\n",
      "Epoch 3/20\n",
      "14106/14106 [==============================] - 18s 1ms/step - loss: 0.3999 - acc: 0.8131 - val_loss: 0.3949 - val_acc: 0.8160\n",
      " ********* seq4-M5 Learning time: 65sec ********* \n",
      "\n",
      "Train_result\n",
      "\n",
      "{'val_loss': [0.404496770498743, 0.3937240863899629, 0.39487690355883065], 'val_acc': [0.8126730371670551, 0.8187451129457558, 0.8160251309115245], 'loss': [0.4388849598607932, 0.409648768964024, 0.3998509357072911], 'acc': [0.7891387390478544, 0.8065654185331073, 0.8131093159307407]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:711: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:724: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M5 -sequence RNN *******************\n",
      "len(y_test_activity) 9251\n",
      "predictY [[0 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 1 1 1 1]\n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 1 1 1 1 1 1 1]]\n",
      "len(predictY) 9251\n",
      "Total test accuracy : 68.25\n",
      "\n",
      "Confusion Matrix\n",
      "[[2051 1701]\n",
      " [1236 4263]]\n",
      "\n",
      "f1_score: 74.38\n",
      "precision_score: 71.48\n",
      "recall_score: 77.52\n",
      "Predict 0: 35.53\n",
      "Predict 1: 64.47\n",
      "\n",
      "71.48 77.52 74.38 68.25\n",
      "\n",
      "\n",
      "Total length:  30428\n",
      "emb_std: 7\n",
      "seq_std: 4\n",
      "train_balancing False\n",
      "CV 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:258: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:271: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:382: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"ou...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:434: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"mi...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M3-RNN *******************\n",
      "\n",
      "\n",
      "******************* M5- seqence RNN *******************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:475: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ba...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:529: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ti...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_69 (InputLayer)        (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "masking_53 (Masking)         (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "forwards_1 (LSTM)            (None, 10, 256)           467968    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 10, 256)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_13 (TimeDis (None, 10, 2)             514       \n",
      "=================================================================\n",
      "Total params: 468,482\n",
      "Trainable params: 468,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16457 samples, validate on 2905 samples\n",
      "Epoch 1/20\n",
      "16457/16457 [==============================] - 33s 2ms/step - loss: 0.4732 - acc: 0.7700 - val_loss: 0.4543 - val_acc: 0.7819\n",
      "Epoch 2/20\n",
      "16457/16457 [==============================] - 21s 1ms/step - loss: 0.4550 - acc: 0.7802 - val_loss: 0.4476 - val_acc: 0.7861\n",
      "Epoch 3/20\n",
      "16457/16457 [==============================] - 21s 1ms/step - loss: 0.4487 - acc: 0.7857 - val_loss: 0.4460 - val_acc: 0.7870\n",
      "Epoch 4/20\n",
      "16457/16457 [==============================] - 21s 1ms/step - loss: 0.4444 - acc: 0.7863 - val_loss: 0.4437 - val_acc: 0.7886\n",
      "Epoch 5/20\n",
      "16457/16457 [==============================] - 21s 1ms/step - loss: 0.4418 - acc: 0.7883 - val_loss: 0.4442 - val_acc: 0.7865\n",
      " ********* seq4-M5 Learning time: 117sec ********* \n",
      "\n",
      "Train_result\n",
      "\n",
      "{'val_loss': [0.45425932102687594, 0.4475580990314484, 0.4460023828504828, 0.4437350365463099, 0.44418669030095953], 'val_acc': [0.7819125574550202, 0.7860603922820953, 0.7869616831231241, 0.7886449448623263, 0.7864760996757809], 'loss': [0.4731762661471462, 0.45502541587413164, 0.44872169292493935, 0.44438459700872246, 0.44177671651790373], 'acc': [0.7699621594270176, 0.7802485336783359, 0.7857228445131738, 0.7862812675109659, 0.7882627319824568]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:711: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:724: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M5 -sequence RNN *******************\n",
      "len(y_test_activity) 8929\n",
      "predictY [[0 1 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 1 1 1 1]\n",
      " [0 0 0 0 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]]\n",
      "len(predictY) 8929\n",
      "Total test accuracy : 67.66\n",
      "\n",
      "Confusion Matrix\n",
      "[[1947 1604]\n",
      " [1284 4094]]\n",
      "\n",
      "f1_score: 73.93\n",
      "precision_score: 71.85\n",
      "recall_score: 76.12\n",
      "Predict 0: 36.19\n",
      "Predict 1: 63.81\n",
      "\n",
      "71.85 76.12 73.93 67.66\n",
      "\n",
      "\n",
      "Total length:  30428\n",
      "emb_std: 7\n",
      "seq_std: 4\n",
      "train_balancing False\n",
      "CV 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:258: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:271: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:382: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"ou...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:434: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"mi...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M3-RNN *******************\n",
      "\n",
      "\n",
      "******************* M5- seqence RNN *******************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:475: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ba...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:529: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ti...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_74 (InputLayer)        (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "masking_57 (Masking)         (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "forwards_1 (LSTM)            (None, 10, 256)           467968    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 10, 256)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_14 (TimeDis (None, 10, 2)             514       \n",
      "=================================================================\n",
      "Total params: 468,482\n",
      "Trainable params: 468,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 18808 samples, validate on 3320 samples\n",
      "Epoch 1/20\n",
      "18808/18808 [==============================] - 36s 2ms/step - loss: 0.4251 - acc: 0.7977 - val_loss: 0.4059 - val_acc: 0.8132\n",
      "Epoch 2/20\n",
      "18808/18808 [==============================] - 24s 1ms/step - loss: 0.4048 - acc: 0.8088 - val_loss: 0.4020 - val_acc: 0.8100\n",
      "Epoch 3/20\n",
      "18808/18808 [==============================] - 24s 1ms/step - loss: 0.3983 - acc: 0.8140 - val_loss: 0.4028 - val_acc: 0.8080\n",
      " ********* seq4-M5 Learning time: 84sec ********* \n",
      "\n",
      "Train_result\n",
      "\n",
      "{'val_loss': [0.40591112942580715, 0.4020215979541641, 0.4028036013425115], 'val_acc': [0.8131706114274909, 0.8099756167595645, 0.807982406846012], 'loss': [0.4251374468708079, 0.40477263516742895, 0.3982894701914096], 'acc': [0.7976867546177275, 0.8087740465966958, 0.8140305440408633]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:711: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:724: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M5 -sequence RNN *******************\n",
      "len(y_test_activity) 8889\n",
      "predictY [[1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 0 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [0 1 0 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 0 0 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 0 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 0 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]]\n",
      "len(predictY) 8889\n",
      "Total test accuracy : 66.32\n",
      "\n",
      "Confusion Matrix\n",
      "[[1559 1940]\n",
      " [1054 4336]]\n",
      "\n",
      "f1_score: 74.34\n",
      "precision_score: 69.09\n",
      "recall_score: 80.45\n",
      "Predict 0: 29.40\n",
      "Predict 1: 70.60\n",
      "\n",
      "69.09 80.45 74.34 66.32\n",
      "\n",
      "\n",
      "Total length:  30428\n",
      "emb_std: 7\n",
      "seq_std: 4\n",
      "train_balancing False\n",
      "CV 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:258: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:271: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:382: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"ou...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:434: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"mi...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M3-RNN *******************\n",
      "\n",
      "\n",
      "******************* M5- seqence RNN *******************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:475: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ba...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:529: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ti...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_79 (InputLayer)        (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "masking_61 (Masking)         (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "forwards_1 (LSTM)            (None, 10, 256)           467968    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 10, 256)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_15 (TimeDis (None, 10, 2)             514       \n",
      "=================================================================\n",
      "Total params: 468,482\n",
      "Trainable params: 468,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 21159 samples, validate on 3735 samples\n",
      "Epoch 1/20\n",
      "21159/21159 [==============================] - 36s 2ms/step - loss: 0.5380 - acc: 0.7227 - val_loss: 0.5265 - val_acc: 0.7310\n",
      "Epoch 2/20\n",
      "21159/21159 [==============================] - 24s 1ms/step - loss: 0.5238 - acc: 0.7299 - val_loss: 0.5281 - val_acc: 0.7309\n",
      " ********* seq4-M5 Learning time: 60sec ********* \n",
      "\n",
      "Train_result\n",
      "\n",
      "{'val_loss': [0.5265400295835263, 0.5281149499866379], 'val_acc': [0.7310321229369127, 0.7309380801806009], 'loss': [0.5379533119483133, 0.5238314679605455], 'acc': [0.7227402205046705, 0.7298867685187825]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:711: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:724: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M5 -sequence RNN *******************\n",
      "len(y_test_activity) 9045\n",
      "predictY [[1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 1 1 1 1 1 1]\n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 0 0 0 0 0 0 0 0]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]]\n",
      "len(predictY) 9045\n",
      "Total test accuracy : 68.98\n",
      "\n",
      "Confusion Matrix\n",
      "[[2106 1620]\n",
      " [1186 4133]]\n",
      "\n",
      "f1_score: 74.66\n",
      "precision_score: 71.84\n",
      "recall_score: 77.70\n",
      "Predict 0: 36.40\n",
      "Predict 1: 63.60\n",
      "\n",
      "71.84 77.70 74.66 68.98\n",
      "\n",
      "\n",
      "Total length:  30428\n",
      "emb_std: 7\n",
      "seq_std: 4\n",
      "train_balancing False\n",
      "CV 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:258: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:271: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:382: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"ou...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:434: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"mi...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M3-RNN *******************\n",
      "\n",
      "\n",
      "******************* M5- seqence RNN *******************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:475: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ba...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:529: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ti...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_84 (InputLayer)        (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "masking_65 (Masking)         (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "forwards_1 (LSTM)            (None, 10, 256)           467968    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 10, 256)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_16 (TimeDis (None, 10, 2)             514       \n",
      "=================================================================\n",
      "Total params: 468,482\n",
      "Trainable params: 468,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 23511 samples, validate on 4149 samples\n",
      "Epoch 1/20\n",
      "23511/23511 [==============================] - 43s 2ms/step - loss: 0.4298 - acc: 0.7965 - val_loss: 0.4150 - val_acc: 0.8046\n",
      "Epoch 2/20\n",
      "23511/23511 [==============================] - 31s 1ms/step - loss: 0.4131 - acc: 0.8044 - val_loss: 0.4129 - val_acc: 0.8084\n",
      "Epoch 3/20\n",
      "23511/23511 [==============================] - 31s 1ms/step - loss: 0.4077 - acc: 0.8080 - val_loss: 0.4097 - val_acc: 0.8086\n",
      "Epoch 4/20\n",
      "23511/23511 [==============================] - 31s 1ms/step - loss: 0.4039 - acc: 0.8094 - val_loss: 0.4084 - val_acc: 0.8090\n",
      "Epoch 5/20\n",
      "23511/23511 [==============================] - 31s 1ms/step - loss: 0.4021 - acc: 0.8114 - val_loss: 0.4099 - val_acc: 0.8084\n",
      " ********* seq4-M5 Learning time: 165sec ********* \n",
      "\n",
      "Train_result\n",
      "\n",
      "{'val_loss': [0.41498092674553955, 0.41294140284479197, 0.4097184514347172, 0.4083769399736496, 0.4098546188490797], 'val_acc': [0.8045942947846718, 0.8084086668752826, 0.808610418771485, 0.8089866827096844, 0.8083888330238933], 'loss': [0.4297564163525818, 0.41310341121474947, 0.4076650056574925, 0.4039259505357601, 0.4020709741701704], 'acc': [0.7965243730899564, 0.8043589212108432, 0.8079954712922578, 0.8093676166493659, 0.8113541265503653]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:711: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:724: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M5 -sequence RNN *******************\n",
      "len(y_test_activity) 9173\n",
      "predictY [[0 0 0 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 0 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 0 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]]\n",
      "len(predictY) 9173\n",
      "Total test accuracy : 68.13\n",
      "\n",
      "Confusion Matrix\n",
      "[[2014 1757]\n",
      " [1166 4236]]\n",
      "\n",
      "f1_score: 74.35\n",
      "precision_score: 70.68\n",
      "recall_score: 78.42\n",
      "Predict 0: 34.67\n",
      "Predict 1: 65.33\n",
      "\n",
      "70.68 78.42 74.35 68.13\n",
      "\n",
      "\n",
      "****************** 4 M5_runT, average : [65.07326579093933, 117.7519862651825, 84.4814510345459, 60.403159379959106, 165.73779964447021] 98.68953242301941 ******************\n",
      "\n",
      "\n",
      "class 1 비율 45.72954270457296\n",
      "Total length:  30428\n",
      "emb_std: 7\n",
      "seq_std: 3\n",
      "train_balancing False\n",
      "CV 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:258: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:271: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:382: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"ou...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:434: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"mi...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M3-RNN *******************\n",
      "\n",
      "\n",
      "******************* M5- seqence RNN *******************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:475: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ba...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:529: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ti...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_89 (InputLayer)        (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "masking_69 (Masking)         (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "forwards_1 (LSTM)            (None, 10, 256)           467968    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 10, 256)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_17 (TimeDis (None, 10, 2)             514       \n",
      "=================================================================\n",
      "Total params: 468,482\n",
      "Trainable params: 468,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 14106 samples, validate on 2490 samples\n",
      "Epoch 1/20\n",
      "14106/14106 [==============================] - 33s 2ms/step - loss: 0.4519 - acc: 0.7865 - val_loss: 0.4341 - val_acc: 0.7909\n",
      "Epoch 2/20\n",
      "14106/14106 [==============================] - 18s 1ms/step - loss: 0.4255 - acc: 0.7990 - val_loss: 0.4232 - val_acc: 0.7993\n",
      "Epoch 3/20\n",
      "14106/14106 [==============================] - 18s 1ms/step - loss: 0.4147 - acc: 0.8058 - val_loss: 0.4196 - val_acc: 0.8001\n",
      "Epoch 4/20\n",
      "14106/14106 [==============================] - 18s 1ms/step - loss: 0.4098 - acc: 0.8096 - val_loss: 0.4223 - val_acc: 0.8026\n",
      " ********* seq3-M5 Learning time: 88sec ********* \n",
      "\n",
      "Train_result\n",
      "\n",
      "{'val_loss': [0.4340613652664016, 0.4232023737756124, 0.41957821716745214, 0.42232846940856383], 'val_acc': [0.7909109615417849, 0.7992789320198886, 0.8000942259907243, 0.8025799084858722], 'loss': [0.4518763055095567, 0.42553549477196445, 0.41469783926118303, 0.40980881253962786], 'acc': [0.7864642972204511, 0.7990069451119804, 0.8057843187371501, 0.8095706870974031]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:711: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:724: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M5 -sequence RNN *******************\n",
      "len(y_test_activity) 9251\n",
      "predictY [[0 0 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 1 1 1]\n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 1 1 1 1 1 1]]\n",
      "len(predictY) 9251\n",
      "Total test accuracy : 68.28\n",
      "\n",
      "Confusion Matrix\n",
      "[[2798 1459]\n",
      " [1475 3519]]\n",
      "\n",
      "f1_score: 70.58\n",
      "precision_score: 70.69\n",
      "recall_score: 70.46\n",
      "Predict 0: 46.19\n",
      "Predict 1: 53.81\n",
      "\n",
      "70.69 70.46 70.58 68.28\n",
      "\n",
      "\n",
      "Total length:  30428\n",
      "emb_std: 7\n",
      "seq_std: 3\n",
      "train_balancing False\n",
      "CV 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:258: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:271: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:382: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"ou...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:434: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"mi...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M3-RNN *******************\n",
      "\n",
      "\n",
      "******************* M5- seqence RNN *******************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:475: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ba...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:529: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ti...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_94 (InputLayer)        (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "masking_73 (Masking)         (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "forwards_1 (LSTM)            (None, 10, 256)           467968    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 10, 256)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_18 (TimeDis (None, 10, 2)             514       \n",
      "=================================================================\n",
      "Total params: 468,482\n",
      "Trainable params: 468,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16457 samples, validate on 2905 samples\n",
      "Epoch 1/20\n",
      "16457/16457 [==============================] - 37s 2ms/step - loss: 0.4844 - acc: 0.7662 - val_loss: 0.4692 - val_acc: 0.7716\n",
      "Epoch 2/20\n",
      "16457/16457 [==============================] - 22s 1ms/step - loss: 0.4656 - acc: 0.7790 - val_loss: 0.4640 - val_acc: 0.7760\n",
      "Epoch 3/20\n",
      "16457/16457 [==============================] - 22s 1ms/step - loss: 0.4590 - acc: 0.7815 - val_loss: 0.4625 - val_acc: 0.7762\n",
      "Epoch 4/20\n",
      "16457/16457 [==============================] - 22s 1ms/step - loss: 0.4561 - acc: 0.7832 - val_loss: 0.4589 - val_acc: 0.7797\n",
      "Epoch 5/20\n",
      "16457/16457 [==============================] - 22s 1ms/step - loss: 0.4530 - acc: 0.7838 - val_loss: 0.4600 - val_acc: 0.7793\n",
      " ********* seq3-M5 Learning time: 126sec ********* \n",
      "\n",
      "Train_result\n",
      "\n",
      "{'val_loss': [0.46916676128792884, 0.4639599289520677, 0.4625312093715865, 0.45889726225767613, 0.4599728827735028], 'val_acc': [0.7715656034096998, 0.7759526790111693, 0.7761703655764897, 0.7797349114015878, 0.779285210586456], 'loss': [0.4844300212496909, 0.4655708562214435, 0.45904868830486834, 0.4561427516622011, 0.45302614603166036], 'acc': [0.76620408285792, 0.7789504196900691, 0.7814963983505748, 0.7831858184435115, 0.7837843530383936]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:711: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:724: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M5 -sequence RNN *******************\n",
      "len(y_test_activity) 8929\n",
      "predictY [[0 1 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 1 1 1 1]\n",
      " [0 0 0 0 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 1 1 1]\n",
      " [0 1 0 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]]\n",
      "len(predictY) 8929\n",
      "Total test accuracy : 68.45\n",
      "\n",
      "Confusion Matrix\n",
      "[[2603 1390]\n",
      " [1427 3509]]\n",
      "\n",
      "f1_score: 71.36\n",
      "precision_score: 71.63\n",
      "recall_score: 71.09\n",
      "Predict 0: 45.13\n",
      "Predict 1: 54.87\n",
      "\n",
      "71.63 71.09 71.36 68.45\n",
      "\n",
      "\n",
      "Total length:  30428\n",
      "emb_std: 7\n",
      "seq_std: 3\n",
      "train_balancing False\n",
      "CV 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:258: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:271: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:382: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"ou...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:434: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"mi...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M3-RNN *******************\n",
      "\n",
      "\n",
      "******************* M5- seqence RNN *******************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:475: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ba...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:529: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ti...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_99 (InputLayer)        (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "masking_77 (Masking)         (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "forwards_1 (LSTM)            (None, 10, 256)           467968    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 10, 256)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_19 (TimeDis (None, 10, 2)             514       \n",
      "=================================================================\n",
      "Total params: 468,482\n",
      "Trainable params: 468,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 18808 samples, validate on 3320 samples\n",
      "Epoch 1/20\n",
      "18808/18808 [==============================] - 39s 2ms/step - loss: 0.4404 - acc: 0.7909 - val_loss: 0.4201 - val_acc: 0.8052\n",
      "Epoch 2/20\n",
      "18808/18808 [==============================] - 24s 1ms/step - loss: 0.4199 - acc: 0.8019 - val_loss: 0.4164 - val_acc: 0.8053\n",
      "Epoch 3/20\n",
      "18808/18808 [==============================] - 24s 1ms/step - loss: 0.4146 - acc: 0.8068 - val_loss: 0.4209 - val_acc: 0.8062\n",
      " ********* seq3-M5 Learning time: 87sec ********* \n",
      "\n",
      "Train_result\n",
      "\n",
      "{'val_loss': [0.42014864991946393, 0.416419940325151, 0.42091391481548907], 'val_acc': [0.8051914295518254, 0.8053193797548133, 0.8062406967921429], 'loss': [0.4403914459990928, 0.41990661751661135, 0.4146199896583046], 'acc': [0.7909470225891525, 0.8019002484342282, 0.8067848292476114]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:711: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:724: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M5 -sequence RNN *******************\n",
      "len(y_test_activity) 8889\n",
      "predictY [[1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 0 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 0 0 1 1 1 1 1 1 1]\n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      " [0 1 0 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 0 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]]\n",
      "len(predictY) 8889\n",
      "Total test accuracy : 66.75\n",
      "\n",
      "Confusion Matrix\n",
      "[[2096 1852]\n",
      " [1104 3837]]\n",
      "\n",
      "f1_score: 72.19\n",
      "precision_score: 67.45\n",
      "recall_score: 77.66\n",
      "Predict 0: 36.00\n",
      "Predict 1: 64.00\n",
      "\n",
      "67.45 77.66 72.19 66.75\n",
      "\n",
      "\n",
      "Total length:  30428\n",
      "emb_std: 7\n",
      "seq_std: 3\n",
      "train_balancing False\n",
      "CV 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:258: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:271: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:382: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"ou...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:434: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"mi...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M3-RNN *******************\n",
      "\n",
      "\n",
      "******************* M5- seqence RNN *******************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:475: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ba...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:529: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ti...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_104 (InputLayer)       (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "masking_81 (Masking)         (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "forwards_1 (LSTM)            (None, 10, 256)           467968    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 10, 256)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_20 (TimeDis (None, 10, 2)             514       \n",
      "=================================================================\n",
      "Total params: 468,482\n",
      "Trainable params: 468,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 21159 samples, validate on 3735 samples\n",
      "Epoch 1/20\n",
      "21159/21159 [==============================] - 43s 2ms/step - loss: 0.5425 - acc: 0.7267 - val_loss: 0.5326 - val_acc: 0.7320\n",
      "Epoch 2/20\n",
      "21159/21159 [==============================] - 27s 1ms/step - loss: 0.5276 - acc: 0.7360 - val_loss: 0.5291 - val_acc: 0.7351\n",
      "Epoch 3/20\n",
      "21159/21159 [==============================] - 27s 1ms/step - loss: 0.5238 - acc: 0.7386 - val_loss: 0.5280 - val_acc: 0.7361\n",
      "Epoch 4/20\n",
      "21159/21159 [==============================] - 27s 1ms/step - loss: 0.5206 - acc: 0.7410 - val_loss: 0.5281 - val_acc: 0.7349\n",
      " ********* seq3-M5 Learning time: 125sec ********* \n",
      "\n",
      "Train_result\n",
      "\n",
      "{'val_loss': [0.5325968665929843, 0.52908832826608, 0.5280449804212833, 0.5280678831589429], 'val_acc': [0.7319672114877815, 0.7351425686354938, 0.7361108306421333, 0.7349104007085164], 'loss': [0.54247321115842, 0.527595601100891, 0.5238338567239417, 0.520569886606421], 'acc': [0.7266857064994557, 0.7359594497672101, 0.7385558303613012, 0.7410354965085473]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:711: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:724: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M5 -sequence RNN *******************\n",
      "len(y_test_activity) 9045\n",
      "predictY [[1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 0 1 1 1 1 1 1]\n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 0 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 1 1 1 1 1 1]\n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 1 1 1 1 1 1]\n",
      " [0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]]\n",
      "len(predictY) 9045\n",
      "Total test accuracy : 69.31\n",
      "\n",
      "Confusion Matrix\n",
      "[[2633 1536]\n",
      " [1240 3636]]\n",
      "\n",
      "f1_score: 72.37\n",
      "precision_score: 70.30\n",
      "recall_score: 74.57\n",
      "Predict 0: 42.82\n",
      "Predict 1: 57.18\n",
      "\n",
      "70.30 74.57 72.37 69.31\n",
      "\n",
      "\n",
      "Total length:  30428\n",
      "emb_std: 7\n",
      "seq_std: 3\n",
      "train_balancing False\n",
      "CV 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:258: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:271: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:382: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"ou...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:434: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"mi...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M3-RNN *******************\n",
      "\n",
      "\n",
      "******************* M5- seqence RNN *******************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:475: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ba...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:529: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ti...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_109 (InputLayer)       (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "masking_85 (Masking)         (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "forwards_1 (LSTM)            (None, 10, 256)           467968    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 10, 256)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_21 (TimeDis (None, 10, 2)             514       \n",
      "=================================================================\n",
      "Total params: 468,482\n",
      "Trainable params: 468,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 23511 samples, validate on 4149 samples\n",
      "Epoch 1/20\n",
      "23511/23511 [==============================] - 47s 2ms/step - loss: 0.4433 - acc: 0.7896 - val_loss: 0.4292 - val_acc: 0.7975\n",
      "Epoch 2/20\n",
      "23511/23511 [==============================] - 30s 1ms/step - loss: 0.4280 - acc: 0.7989 - val_loss: 0.4231 - val_acc: 0.8017\n",
      "Epoch 3/20\n",
      "23511/23511 [==============================] - 30s 1ms/step - loss: 0.4230 - acc: 0.8007 - val_loss: 0.4254 - val_acc: 0.7998\n",
      " ********* seq3-M5 Learning time: 108sec ********* \n",
      "\n",
      "Train_result\n",
      "\n",
      "{'val_loss': [0.429223430159581, 0.42306101586508965, 0.425443645427531], 'val_acc': [0.7974678234152979, 0.8017371463097558, 0.7997695826915237], 'loss': [0.4432541521237661, 0.4280307241664193, 0.4229586219426081], 'acc': [0.7896414590832083, 0.7989287441557965, 0.8007129399258572]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:711: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:724: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M5 -sequence RNN *******************\n",
      "len(y_test_activity) 9173\n",
      "predictY [[0 0 0 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 0 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]]\n",
      "len(predictY) 9173\n",
      "Total test accuracy : 68.70\n",
      "\n",
      "Confusion Matrix\n",
      "[[2527 1687]\n",
      " [1184 3775]]\n",
      "\n",
      "f1_score: 72.45\n",
      "precision_score: 69.11\n",
      "recall_score: 76.12\n",
      "Predict 0: 40.46\n",
      "Predict 1: 59.54\n",
      "\n",
      "69.11 76.12 72.45 68.70\n",
      "\n",
      "\n",
      "****************** 3 M5_runT, average : [88.6277585029602, 126.06706166267395, 87.47658514976501, 125.60828232765198, 108.14448022842407] 107.18483357429504 ******************\n",
      "\n",
      "\n",
      "class 1 비율 53.17346826531735\n",
      "Total length:  30428\n",
      "emb_std: 7\n",
      "seq_std: 2\n",
      "train_balancing False\n",
      "CV 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:258: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:271: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:382: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"ou...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:434: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"mi...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M3-RNN *******************\n",
      "\n",
      "\n",
      "******************* M5- seqence RNN *******************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:475: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ba...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:529: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ti...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_114 (InputLayer)       (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "masking_89 (Masking)         (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "forwards_1 (LSTM)            (None, 10, 256)           467968    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 10, 256)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_22 (TimeDis (None, 10, 2)             514       \n",
      "=================================================================\n",
      "Total params: 468,482\n",
      "Trainable params: 468,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 14106 samples, validate on 2490 samples\n",
      "Epoch 1/20\n",
      "14106/14106 [==============================] - 35s 3ms/step - loss: 0.4538 - acc: 0.7889 - val_loss: 0.4285 - val_acc: 0.8038\n",
      "Epoch 2/20\n",
      "14106/14106 [==============================] - 18s 1ms/step - loss: 0.4213 - acc: 0.8067 - val_loss: 0.4171 - val_acc: 0.8131\n",
      "Epoch 3/20\n",
      "14106/14106 [==============================] - 18s 1ms/step - loss: 0.4121 - acc: 0.8119 - val_loss: 0.4117 - val_acc: 0.8159\n",
      "Epoch 4/20\n",
      "14106/14106 [==============================] - 18s 1ms/step - loss: 0.4050 - acc: 0.8155 - val_loss: 0.4099 - val_acc: 0.8165\n",
      "Epoch 5/20\n",
      "14106/14106 [==============================] - 18s 1ms/step - loss: 0.4012 - acc: 0.8174 - val_loss: 0.4102 - val_acc: 0.8139\n",
      " ********* seq2-M5 Learning time: 109sec ********* \n",
      "\n",
      "Train_result\n",
      "\n",
      "{'val_loss': [0.42846553526728987, 0.41714504844692335, 0.4117223120597472, 0.4099062439428276, 0.4101744621633047], 'val_acc': [0.8037512401021628, 0.8131458563019472, 0.8158961863881613, 0.8164708266775292, 0.81393366003611], 'loss': [0.453768653352768, 0.4212583930470767, 0.4120671769693086, 0.4050229774389506, 0.40123982835488675], 'acc': [0.7888706232425458, 0.806728153072924, 0.8119184215846644, 0.8154956191021822, 0.8173600745238295]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:711: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:724: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M5 -sequence RNN *******************\n",
      "len(y_test_activity) 9251\n",
      "predictY [[0 0 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 1]\n",
      " [0 0 0 0 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 1 1 1 1 1 1]]\n",
      "len(predictY) 9251\n",
      "Total test accuracy : 69.56\n",
      "\n",
      "Confusion Matrix\n",
      "[[3443 1478]\n",
      " [1338 2992]]\n",
      "\n",
      "f1_score: 68.00\n",
      "precision_score: 66.94\n",
      "recall_score: 69.10\n",
      "Predict 0: 51.68\n",
      "Predict 1: 48.32\n",
      "\n",
      "66.94 69.10 68.00 69.56\n",
      "\n",
      "\n",
      "Total length:  30428\n",
      "emb_std: 7\n",
      "seq_std: 2\n",
      "train_balancing False\n",
      "CV 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:258: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:271: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:382: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"ou...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:434: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"mi...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M3-RNN *******************\n",
      "\n",
      "\n",
      "******************* M5- seqence RNN *******************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:475: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ba...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:529: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ti...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_119 (InputLayer)       (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "masking_93 (Masking)         (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "forwards_1 (LSTM)            (None, 10, 256)           467968    \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 10, 256)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_23 (TimeDis (None, 10, 2)             514       \n",
      "=================================================================\n",
      "Total params: 468,482\n",
      "Trainable params: 468,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16457 samples, validate on 2905 samples\n",
      "Epoch 1/20\n",
      "16457/16457 [==============================] - 39s 2ms/step - loss: 0.4871 - acc: 0.7685 - val_loss: 0.4557 - val_acc: 0.7887\n",
      "Epoch 2/20\n",
      "16457/16457 [==============================] - 22s 1ms/step - loss: 0.4670 - acc: 0.7805 - val_loss: 0.4485 - val_acc: 0.7929\n",
      "Epoch 3/20\n",
      "16457/16457 [==============================] - 22s 1ms/step - loss: 0.4596 - acc: 0.7836 - val_loss: 0.4438 - val_acc: 0.7947\n",
      "Epoch 4/20\n",
      "16457/16457 [==============================] - 22s 1ms/step - loss: 0.4544 - acc: 0.7872 - val_loss: 0.4444 - val_acc: 0.7913\n",
      " ********* seq2-M5 Learning time: 105sec ********* \n",
      "\n",
      "Train_result\n",
      "\n",
      "{'val_loss': [0.4557220352701394, 0.4485331223979464, 0.4437668915870062, 0.44437393252697743], 'val_acc': [0.788717830919768, 0.7929099975272423, 0.7946795260639486, 0.7912754139268254], 'loss': [0.4870668627489683, 0.4669748081821656, 0.45955481973708223, 0.4543805477931664], 'acc': [0.7685419341921987, 0.780537373227019, 0.7835831818281028, 0.7872454304158227]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:711: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:724: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M5 -sequence RNN *******************\n",
      "len(y_test_activity) 8929\n",
      "predictY [[0 1 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 1 1 1 1]\n",
      " [0 0 0 0 0 0 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 1 1 1]\n",
      " [0 1 0 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]]\n",
      "len(predictY) 8929\n",
      "Total test accuracy : 69.47\n",
      "\n",
      "Confusion Matrix\n",
      "[[3232 1441]\n",
      " [1285 2971]]\n",
      "\n",
      "f1_score: 68.55\n",
      "precision_score: 67.34\n",
      "recall_score: 69.81\n",
      "Predict 0: 50.59\n",
      "Predict 1: 49.41\n",
      "\n",
      "67.34 69.81 68.55 69.47\n",
      "\n",
      "\n",
      "Total length:  30428\n",
      "emb_std: 7\n",
      "seq_std: 2\n",
      "train_balancing False\n",
      "CV 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:258: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:271: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:382: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"ou...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:434: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"mi...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M3-RNN *******************\n",
      "\n",
      "\n",
      "******************* M5- seqence RNN *******************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:475: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ba...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:529: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ti...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_124 (InputLayer)       (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "masking_97 (Masking)         (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "forwards_1 (LSTM)            (None, 10, 256)           467968    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 10, 256)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_24 (TimeDis (None, 10, 2)             514       \n",
      "=================================================================\n",
      "Total params: 468,482\n",
      "Trainable params: 468,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 18808 samples, validate on 3320 samples\n",
      "Epoch 1/20\n",
      "18808/18808 [==============================] - 43s 2ms/step - loss: 0.4408 - acc: 0.7953 - val_loss: 0.4212 - val_acc: 0.8067\n",
      "Epoch 2/20\n",
      "18808/18808 [==============================] - 25s 1ms/step - loss: 0.4198 - acc: 0.8062 - val_loss: 0.4143 - val_acc: 0.8101\n",
      "Epoch 3/20\n",
      "18808/18808 [==============================] - 25s 1ms/step - loss: 0.4131 - acc: 0.8111 - val_loss: 0.4128 - val_acc: 0.8103\n",
      "Epoch 4/20\n",
      "18808/18808 [==============================] - 25s 1ms/step - loss: 0.4106 - acc: 0.8124 - val_loss: 0.4088 - val_acc: 0.8121\n",
      "Epoch 5/20\n",
      "18808/18808 [==============================] - 25s 1ms/step - loss: 0.4066 - acc: 0.8133 - val_loss: 0.4083 - val_acc: 0.8160\n",
      "Epoch 6/20\n",
      "18808/18808 [==============================] - 25s 1ms/step - loss: 0.4049 - acc: 0.8151 - val_loss: 0.4085 - val_acc: 0.8141\n",
      " ********* seq2-M5 Learning time: 168sec ********* \n",
      "\n",
      "Train_result\n",
      "\n",
      "{'val_loss': [0.42115524267575827, 0.4143120028168322, 0.4127995763198439, 0.4087784931602248, 0.4082625864500023, 0.40854459584477437], 'val_acc': [0.8066623185054366, 0.8100532602114849, 0.8103261963430658, 0.8120525272495775, 0.8159565053790448, 0.8140806084655854], 'loss': [0.4408283603414481, 0.4197973119279569, 0.41309575121081266, 0.4106004467192025, 0.40663018764358333, 0.40490640587676896], 'acc': [0.7952939713067169, 0.806150444286116, 0.8111034463892993, 0.8123654732801517, 0.8133029017180698, 0.8151262416225046]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:711: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:724: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M5 -sequence RNN *******************\n",
      "len(y_test_activity) 8889\n",
      "predictY [[1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 0 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 0 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 0 0 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]]\n",
      "len(predictY) 8889\n",
      "Total test accuracy : 67.88\n",
      "\n",
      "Confusion Matrix\n",
      "[[2951 1653]\n",
      " [1202 3083]]\n",
      "\n",
      "f1_score: 68.35\n",
      "precision_score: 65.10\n",
      "recall_score: 71.95\n",
      "Predict 0: 46.72\n",
      "Predict 1: 53.28\n",
      "\n",
      "65.10 71.95 68.35 67.88\n",
      "\n",
      "\n",
      "Total length:  30428\n",
      "emb_std: 7\n",
      "seq_std: 2\n",
      "train_balancing False\n",
      "CV 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:258: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:271: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:382: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"ou...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:434: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"mi...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M3-RNN *******************\n",
      "\n",
      "\n",
      "******************* M5- seqence RNN *******************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:475: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ba...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:529: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ti...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_129 (InputLayer)       (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "masking_101 (Masking)        (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "forwards_1 (LSTM)            (None, 10, 256)           467968    \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 10, 256)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_25 (TimeDis (None, 10, 2)             514       \n",
      "=================================================================\n",
      "Total params: 468,482\n",
      "Trainable params: 468,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 21159 samples, validate on 3735 samples\n",
      "Epoch 1/20\n",
      "21159/21159 [==============================] - 47s 2ms/step - loss: 0.5353 - acc: 0.7404 - val_loss: 0.5270 - val_acc: 0.7402\n",
      "Epoch 2/20\n",
      "21159/21159 [==============================] - 28s 1ms/step - loss: 0.5214 - acc: 0.7480 - val_loss: 0.5244 - val_acc: 0.7471\n",
      "Epoch 3/20\n",
      "21159/21159 [==============================] - 28s 1ms/step - loss: 0.5164 - acc: 0.7515 - val_loss: 0.5189 - val_acc: 0.7488\n",
      "Epoch 4/20\n",
      "21159/21159 [==============================] - 28s 1ms/step - loss: 0.5132 - acc: 0.7530 - val_loss: 0.5172 - val_acc: 0.7510\n",
      "Epoch 5/20\n",
      "21159/21159 [==============================] - 28s 1ms/step - loss: 0.5112 - acc: 0.7547 - val_loss: 0.5193 - val_acc: 0.7485\n",
      " ********* seq2-M5 Learning time: 161sec ********* \n",
      "\n",
      "Train_result\n",
      "\n",
      "{'val_loss': [0.5270161051188447, 0.5243869605233551, 0.5189098772195129, 0.5172114144048219, 0.519277694889181], 'val_acc': [0.7402240529117814, 0.7471034953233547, 0.7487966845153645, 0.7510473922872479, 0.7484582433738862], 'loss': [0.5353291236253963, 0.5213768101069803, 0.5163876908426841, 0.5132070548610227, 0.5111671274723247], 'acc': [0.740395120698544, 0.7480118432749906, 0.7515404317863407, 0.7529912916877848, 0.7547356488827615]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:711: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:724: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M5 -sequence RNN *******************\n",
      "len(y_test_activity) 9045\n",
      "predictY [[1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 0 0 1 1 1 1 1 1]\n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 1 1 1 1 1 1]\n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 1 1 1 1 1 1]\n",
      " [0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]]\n",
      "len(predictY) 9045\n",
      "Total test accuracy : 71.14\n",
      "\n",
      "Confusion Matrix\n",
      "[[3481 1334]\n",
      " [1276 2954]]\n",
      "\n",
      "f1_score: 69.36\n",
      "precision_score: 68.89\n",
      "recall_score: 69.83\n",
      "Predict 0: 52.59\n",
      "Predict 1: 47.41\n",
      "\n",
      "68.89 69.83 69.36 71.14\n",
      "\n",
      "\n",
      "Total length:  30428\n",
      "emb_std: 7\n",
      "seq_std: 2\n",
      "train_balancing False\n",
      "CV 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:258: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:271: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:382: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"ou...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:434: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"mi...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M3-RNN *******************\n",
      "\n",
      "\n",
      "******************* M5- seqence RNN *******************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:475: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ba...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:529: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ti...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_134 (InputLayer)       (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "masking_105 (Masking)        (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "forwards_1 (LSTM)            (None, 10, 256)           467968    \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 10, 256)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_26 (TimeDis (None, 10, 2)             514       \n",
      "=================================================================\n",
      "Total params: 468,482\n",
      "Trainable params: 468,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 23511 samples, validate on 4149 samples\n",
      "Epoch 1/20\n",
      "23511/23511 [==============================] - 51s 2ms/step - loss: 0.4441 - acc: 0.7940 - val_loss: 0.4249 - val_acc: 0.8022\n",
      "Epoch 2/20\n",
      "23511/23511 [==============================] - 32s 1ms/step - loss: 0.4259 - acc: 0.8031 - val_loss: 0.4214 - val_acc: 0.8040\n",
      "Epoch 3/20\n",
      "23511/23511 [==============================] - 32s 1ms/step - loss: 0.4213 - acc: 0.8055 - val_loss: 0.4161 - val_acc: 0.8075\n",
      "Epoch 4/20\n",
      "23511/23511 [==============================] - 32s 1ms/step - loss: 0.4178 - acc: 0.8062 - val_loss: 0.4148 - val_acc: 0.8080\n",
      "Epoch 5/20\n",
      "23511/23511 [==============================] - 32s 1ms/step - loss: 0.4148 - acc: 0.8093 - val_loss: 0.4145 - val_acc: 0.8073\n",
      "Epoch 6/20\n",
      "23511/23511 [==============================] - 32s 1ms/step - loss: 0.4127 - acc: 0.8097 - val_loss: 0.4143 - val_acc: 0.8072\n",
      "Epoch 7/20\n",
      "23511/23511 [==============================] - 31s 1ms/step - loss: 0.4111 - acc: 0.8095 - val_loss: 0.4143 - val_acc: 0.8067\n",
      " ********* seq2-M5 Learning time: 241sec ********* \n",
      "\n",
      "Train_result\n",
      "\n",
      "{'val_loss': [0.42487160767753834, 0.42139419365228015, 0.4161195009479927, 0.41481266585738724, 0.41454958925766666, 0.4142919748439706, 0.41433673116579833], 'val_acc': [0.8022123580382341, 0.8039793473003743, 0.8074531221022, 0.8079912190869447, 0.8072536078152182, 0.8071852928042326, 0.806713775831063], 'loss': [0.44411580590148975, 0.4259376954210443, 0.4212887443104239, 0.4178117922010925, 0.4147657835305074, 0.4126672146752439, 0.4110754256114414], 'acc': [0.7940210235995532, 0.8030829180443506, 0.8055482304850184, 0.8062243917130242, 0.8093106078729397, 0.809676821190975, 0.8095319795971558]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:711: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:724: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M5 -sequence RNN *******************\n",
      "len(y_test_activity) 9173\n",
      "predictY [[0 0 0 0 1 0 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]]\n",
      "len(predictY) 9173\n",
      "Total test accuracy : 69.66\n",
      "\n",
      "Confusion Matrix\n",
      "[[3452 1409]\n",
      " [1374 2938]]\n",
      "\n",
      "f1_score: 67.86\n",
      "precision_score: 67.59\n",
      "recall_score: 68.14\n",
      "Predict 0: 52.61\n",
      "Predict 1: 47.39\n",
      "\n",
      "67.59 68.14 67.86 69.66\n",
      "\n",
      "\n",
      "****************** 2 M5_runT, average : [109.73990607261658, 105.10602903366089, 168.7465627193451, 161.17091345787048, 241.37688279151917] 157.22805881500244 ******************\n",
      "\n",
      "\n",
      "class 1 비율 63.224367756322444\n",
      "Total length:  30428\n",
      "emb_std: 7\n",
      "seq_std: 1\n",
      "train_balancing False\n",
      "CV 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:258: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:271: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:382: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"ou...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:434: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"mi...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M3-RNN *******************\n",
      "\n",
      "\n",
      "******************* M5- seqence RNN *******************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:475: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ba...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:529: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ti...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_139 (InputLayer)       (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "masking_109 (Masking)        (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "forwards_1 (LSTM)            (None, 10, 256)           467968    \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 10, 256)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_27 (TimeDis (None, 10, 2)             514       \n",
      "=================================================================\n",
      "Total params: 468,482\n",
      "Trainable params: 468,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 14106 samples, validate on 2490 samples\n",
      "Epoch 1/20\n",
      "14106/14106 [==============================] - 40s 3ms/step - loss: 0.4279 - acc: 0.8041 - val_loss: 0.3952 - val_acc: 0.8208\n",
      "Epoch 2/20\n",
      "14106/14106 [==============================] - 19s 1ms/step - loss: 0.3974 - acc: 0.8226 - val_loss: 0.3854 - val_acc: 0.8243\n",
      "Epoch 3/20\n",
      "14106/14106 [==============================] - 19s 1ms/step - loss: 0.3869 - acc: 0.8288 - val_loss: 0.3828 - val_acc: 0.8272\n",
      "Epoch 4/20\n",
      "14106/14106 [==============================] - 19s 1ms/step - loss: 0.3812 - acc: 0.8322 - val_loss: 0.3760 - val_acc: 0.8314\n",
      "Epoch 5/20\n",
      "14106/14106 [==============================] - 19s 1ms/step - loss: 0.3752 - acc: 0.8350 - val_loss: 0.3753 - val_acc: 0.8334\n",
      "Epoch 6/20\n",
      "14106/14106 [==============================] - 19s 1ms/step - loss: 0.3712 - acc: 0.8376 - val_loss: 0.3746 - val_acc: 0.8295\n",
      "Epoch 7/20\n",
      "14106/14106 [==============================] - 19s 1ms/step - loss: 0.3653 - acc: 0.8404 - val_loss: 0.3727 - val_acc: 0.8333\n",
      "Epoch 8/20\n",
      "14106/14106 [==============================] - 19s 1ms/step - loss: 0.3624 - acc: 0.8429 - val_loss: 0.3739 - val_acc: 0.8338\n",
      " ********* seq1-M5 Learning time: 174sec ********* \n",
      "\n",
      "Train_result\n",
      "\n",
      "{'val_loss': [0.3951975955781209, 0.38544935435655125, 0.3827953404690846, 0.3760213002861743, 0.37526090982927374, 0.37456068588069164, 0.3726662789243292, 0.3739355835330534], 'val_acc': [0.8208407426933687, 0.8242624559076914, 0.8271838569736863, 0.8314400640836203, 0.833432499424042, 0.8295137666315439, 0.8333158456178076, 0.8337643026826851], 'loss': [0.4279459591040658, 0.39735405023902864, 0.38690820736917525, 0.38119496557875826, 0.3751593258775381, 0.37122442942721684, 0.3652987431232496, 0.3623673801310228], 'acc': [0.8041026221595384, 0.8225552193766602, 0.8288344621286483, 0.8321527928878749, 0.8350266919868915, 0.8375756671525697, 0.8403981216035294, 0.842878250412851]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:711: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:724: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M5 -sequence RNN *******************\n",
      "len(y_test_activity) 9251\n",
      "predictY [[0 0 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 1]\n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 1 1 1 1 1 1]]\n",
      "len(predictY) 9251\n",
      "Total test accuracy : 72.58\n",
      "\n",
      "Confusion Matrix\n",
      "[[4430 1400]\n",
      " [1137 2284]]\n",
      "\n",
      "f1_score: 64.29\n",
      "precision_score: 62.00\n",
      "recall_score: 66.76\n",
      "Predict 0: 60.18\n",
      "Predict 1: 39.82\n",
      "\n",
      "62.00 66.76 64.29 72.58\n",
      "\n",
      "\n",
      "Total length:  30428\n",
      "emb_std: 7\n",
      "seq_std: 1\n",
      "train_balancing False\n",
      "CV 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:258: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:271: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:382: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"ou...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:434: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"mi...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M3-RNN *******************\n",
      "\n",
      "\n",
      "******************* M5- seqence RNN *******************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:475: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ba...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:529: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ti...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_144 (InputLayer)       (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "masking_113 (Masking)        (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "forwards_1 (LSTM)            (None, 10, 256)           467968    \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 10, 256)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_28 (TimeDis (None, 10, 2)             514       \n",
      "=================================================================\n",
      "Total params: 468,482\n",
      "Trainable params: 468,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16457 samples, validate on 2905 samples\n",
      "Epoch 1/20\n",
      "16457/16457 [==============================] - 44s 3ms/step - loss: 0.4559 - acc: 0.7893 - val_loss: 0.4380 - val_acc: 0.8013\n",
      "Epoch 2/20\n",
      "16457/16457 [==============================] - 23s 1ms/step - loss: 0.4330 - acc: 0.8036 - val_loss: 0.4306 - val_acc: 0.8052\n",
      "Epoch 3/20\n",
      "16457/16457 [==============================] - 23s 1ms/step - loss: 0.4262 - acc: 0.8074 - val_loss: 0.4309 - val_acc: 0.8046\n",
      " ********* seq1-M5 Learning time: 89sec ********* \n",
      "\n",
      "Train_result\n",
      "\n",
      "{'val_loss': [0.43800144197608437, 0.43063467946192074, 0.4308859091514975], 'val_acc': [0.8012970905500928, 0.8051642402314073, 0.8046066227550146], 'loss': [0.4559267389370125, 0.4329663218244817, 0.4261739739904052], 'acc': [0.7893239978220756, 0.8036295056828405, 0.8073860560514124]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:711: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:724: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M5 -sequence RNN *******************\n",
      "len(y_test_activity) 8929\n",
      "predictY [[0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]]\n",
      "len(predictY) 8929\n",
      "Total test accuracy : 72.20\n",
      "\n",
      "Confusion Matrix\n",
      "[[4594  966]\n",
      " [1516 1853]]\n",
      "\n",
      "f1_score: 59.89\n",
      "precision_score: 65.73\n",
      "recall_score: 55.00\n",
      "Predict 0: 68.43\n",
      "Predict 1: 31.57\n",
      "\n",
      "65.73 55.00 59.89 72.20\n",
      "\n",
      "\n",
      "Total length:  30428\n",
      "emb_std: 7\n",
      "seq_std: 1\n",
      "train_balancing False\n",
      "CV 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:258: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:271: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:382: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"ou...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:434: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"mi...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M3-RNN *******************\n",
      "\n",
      "\n",
      "******************* M5- seqence RNN *******************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:475: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ba...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:529: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ti...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_149 (InputLayer)       (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "masking_117 (Masking)        (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "forwards_1 (LSTM)            (None, 10, 256)           467968    \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 10, 256)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_29 (TimeDis (None, 10, 2)             514       \n",
      "=================================================================\n",
      "Total params: 468,482\n",
      "Trainable params: 468,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 18808 samples, validate on 3320 samples\n",
      "Epoch 1/20\n",
      "18808/18808 [==============================] - 48s 3ms/step - loss: 0.4164 - acc: 0.8113 - val_loss: 0.3999 - val_acc: 0.8169\n",
      "Epoch 2/20\n",
      "18808/18808 [==============================] - 26s 1ms/step - loss: 0.3925 - acc: 0.8238 - val_loss: 0.3948 - val_acc: 0.8191\n",
      "Epoch 3/20\n",
      "18808/18808 [==============================] - 26s 1ms/step - loss: 0.3854 - acc: 0.8271 - val_loss: 0.3918 - val_acc: 0.8213\n",
      "Epoch 4/20\n",
      "18808/18808 [==============================] - 26s 1ms/step - loss: 0.3820 - acc: 0.8287 - val_loss: 0.3922 - val_acc: 0.8217\n",
      " ********* seq1-M5 Learning time: 125sec ********* \n",
      "\n",
      "Train_result\n",
      "\n",
      "{'val_loss': [0.39987827008029064, 0.3947791842092951, 0.3918436568903636, 0.392183429361826], 'val_acc': [0.8168541106833033, 0.8190649621457938, 0.8213461430676012, 0.8217477662017546], 'loss': [0.4163567722604306, 0.3925025120713466, 0.3854291034424269, 0.38202260825695866], 'acc': [0.8113362403283064, 0.8237614082509231, 0.8271286617132615, 0.8287103968901819]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:711: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:724: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M5 -sequence RNN *******************\n",
      "len(y_test_activity) 8889\n",
      "predictY [[1 1 0 0 1 1 1 1 1 1]\n",
      " [0 1 0 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 1 1 1 1 1 1]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      " [1 1 0 0 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 0 0 0 0 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 1 1 1]\n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 1 1 1 1 1 1]\n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]]\n",
      "len(predictY) 8889\n",
      "Total test accuracy : 72.06\n",
      "\n",
      "Confusion Matrix\n",
      "[[4273 1245]\n",
      " [1239 2132]]\n",
      "\n",
      "f1_score: 63.19\n",
      "precision_score: 63.13\n",
      "recall_score: 63.25\n",
      "Predict 0: 62.01\n",
      "Predict 1: 37.99\n",
      "\n",
      "63.13 63.25 63.19 72.06\n",
      "\n",
      "\n",
      "Total length:  30428\n",
      "emb_std: 7\n",
      "seq_std: 1\n",
      "train_balancing False\n",
      "CV 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:258: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:271: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:382: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"ou...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:434: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"mi...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M3-RNN *******************\n",
      "\n",
      "\n",
      "******************* M5- seqence RNN *******************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:475: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ba...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:529: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ti...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_154 (InputLayer)       (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "masking_121 (Masking)        (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "forwards_1 (LSTM)            (None, 10, 256)           467968    \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 10, 256)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_30 (TimeDis (None, 10, 2)             514       \n",
      "=================================================================\n",
      "Total params: 468,482\n",
      "Trainable params: 468,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 21159 samples, validate on 3735 samples\n",
      "Epoch 1/20\n",
      "21159/21159 [==============================] - 52s 2ms/step - loss: 0.4991 - acc: 0.7652 - val_loss: 0.4928 - val_acc: 0.7770\n",
      "Epoch 2/20\n",
      "21159/21159 [==============================] - 29s 1ms/step - loss: 0.4818 - acc: 0.7785 - val_loss: 0.4815 - val_acc: 0.7803\n",
      "Epoch 3/20\n",
      "21159/21159 [==============================] - 29s 1ms/step - loss: 0.4777 - acc: 0.7797 - val_loss: 0.4786 - val_acc: 0.7813\n",
      "Epoch 4/20\n",
      "21159/21159 [==============================] - 29s 1ms/step - loss: 0.4746 - acc: 0.7823 - val_loss: 0.4778 - val_acc: 0.7839\n",
      "Epoch 5/20\n",
      "21159/21159 [==============================] - 29s 1ms/step - loss: 0.4725 - acc: 0.7823 - val_loss: 0.4770 - val_acc: 0.7851\n",
      "Epoch 6/20\n",
      "21159/21159 [==============================] - 29s 1ms/step - loss: 0.4712 - acc: 0.7832 - val_loss: 0.4755 - val_acc: 0.7839\n",
      "Epoch 7/20\n",
      "21159/21159 [==============================] - 29s 1ms/step - loss: 0.4698 - acc: 0.7835 - val_loss: 0.4758 - val_acc: 0.7862\n",
      " ********* seq1-M5 Learning time: 228sec ********* \n",
      "\n",
      "Train_result\n",
      "\n",
      "{'val_loss': [0.49281626070838375, 0.4814920801554658, 0.4785914404165633, 0.47783670873846235, 0.47697638694541045, 0.47551766344342367, 0.47580424998020393], 'val_acc': [0.7770357138181786, 0.7803043318082051, 0.7812634444300589, 0.7839492837268824, 0.7851077273029241, 0.7839384419053115, 0.7861517582392916], 'loss': [0.4990655750753163, 0.4817844545214719, 0.4777011645316875, 0.4746135935166917, 0.47245731345139785, 0.47116789194861375, 0.4698232180598756], 'acc': [0.7651640407681561, 0.7784996559576072, 0.7796855024981799, 0.7823250532781274, 0.7822720546443869, 0.7831922968876566, 0.7834965845487131]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:711: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:724: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M5 -sequence RNN *******************\n",
      "len(y_test_activity) 9045\n",
      "predictY [[0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 1 1 1 1 1]\n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 1 1 1 1 1 1 1 1]]\n",
      "len(predictY) 9045\n",
      "Total test accuracy : 75.35\n",
      "\n",
      "Confusion Matrix\n",
      "[[4710  959]\n",
      " [1271 2105]]\n",
      "\n",
      "f1_score: 65.37\n",
      "precision_score: 68.70\n",
      "recall_score: 62.35\n",
      "Predict 0: 66.12\n",
      "Predict 1: 33.88\n",
      "\n",
      "68.70 62.35 65.37 75.35\n",
      "\n",
      "\n",
      "Total length:  30428\n",
      "emb_std: 7\n",
      "seq_std: 1\n",
      "train_balancing False\n",
      "CV 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:258: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:271: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:382: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"ou...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:434: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"mi...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M3-RNN *******************\n",
      "\n",
      "\n",
      "******************* M5- seqence RNN *******************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:475: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ba...)`\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:529: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ti...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_159 (InputLayer)       (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "masking_125 (Masking)        (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "forwards_1 (LSTM)            (None, 10, 256)           467968    \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 10, 256)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_31 (TimeDis (None, 10, 2)             514       \n",
      "=================================================================\n",
      "Total params: 468,482\n",
      "Trainable params: 468,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 23511 samples, validate on 4149 samples\n",
      "Epoch 1/20\n",
      "23511/23511 [==============================] - 57s 2ms/step - loss: 0.4177 - acc: 0.8113 - val_loss: 0.3972 - val_acc: 0.8237\n",
      "Epoch 2/20\n",
      "23511/23511 [==============================] - 33s 1ms/step - loss: 0.3998 - acc: 0.8201 - val_loss: 0.3927 - val_acc: 0.8259\n",
      "Epoch 3/20\n",
      "23511/23511 [==============================] - 33s 1ms/step - loss: 0.3950 - acc: 0.8236 - val_loss: 0.3917 - val_acc: 0.8250\n",
      "Epoch 4/20\n",
      "23511/23511 [==============================] - 33s 1ms/step - loss: 0.3922 - acc: 0.8250 - val_loss: 0.3879 - val_acc: 0.8285\n",
      "Epoch 5/20\n",
      "23511/23511 [==============================] - 33s 1ms/step - loss: 0.3901 - acc: 0.8252 - val_loss: 0.3885 - val_acc: 0.8249\n",
      " ********* seq1-M5 Learning time: 189sec ********* \n",
      "\n",
      "Train_result\n",
      "\n",
      "{'val_loss': [0.39720745178899813, 0.39272425895313035, 0.39171105234644216, 0.3878623631653311, 0.38851542430028596], 'val_acc': [0.8236555634679263, 0.8258829113229782, 0.824975827755081, 0.828498018006297, 0.8248713970845163], 'loss': [0.41769971915629145, 0.3997839367527593, 0.39496819207671446, 0.392165556274325, 0.3901082503347404], 'acc': [0.8112713481414415, 0.8200788531389196, 0.8236335558288126, 0.8249672983323573, 0.8252222513960867]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:711: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/yksi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:724: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* M5 -sequence RNN *******************\n",
      "len(y_test_activity) 9173\n",
      "predictY [[0 0 0 0 1 0 0 0 0 0]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]]\n",
      "len(predictY) 9173\n",
      "Total test accuracy : 73.06\n",
      "\n",
      "Confusion Matrix\n",
      "[[4460 1307]\n",
      " [1164 2242]]\n",
      "\n",
      "f1_score: 64.47\n",
      "precision_score: 63.17\n",
      "recall_score: 65.83\n",
      "Predict 0: 61.31\n",
      "Predict 1: 38.69\n",
      "\n",
      "63.17 65.83 64.47 73.06\n",
      "\n",
      "\n",
      "****************** 1 M5_runT, average : [174.11006712913513, 89.66933131217957, 125.82337212562561, 228.3580765724182, 189.01551985740662] 161.39527339935302 ******************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# seq-task implement\n",
    "\n",
    "auto_balancing=False\n",
    "train_balancing=False\n",
    "data_name = {mozilla:'mozilla', chrome:'chrome', firefox:'firefox', eclipse:'eclipse'}\n",
    "#[0]:workday [1]:openday [2]:activityCnt [3]:cc \n",
    "total_split = {'firefox': [[3,7],[1,2,3,10,30],[3,7,20,50],[1,2,3]], 'chrome':[[3,7],[1,2,3,10,30],[1,2,5,10],[1,2,3]], 'eclipse':[[3,7],[1,2,3,10,30],[1,2,3,5],[1,2,3]]} \n",
    "\n",
    "test_mode = False\n",
    "if test_mode: save_off = True\n",
    "else: save_off = False\n",
    "save_off=True\n",
    "\n",
    "emb_load = True\n",
    "\n",
    "max_activity_len = 10\n",
    "min_activity_len = 1 # workday 1-10\n",
    "lambda_list = [7]\n",
    "\n",
    "\n",
    "#Task Type\n",
    "bidirectional = False\n",
    "ResLSTM = True\n",
    "task_mlp = False\n",
    "\n",
    "task2_nextAct = False\n",
    "task3_outlier = False\n",
    "task4_lifetime = False\n",
    "task5_multiFixtime = False\n",
    "\n",
    "# data size\n",
    "d_sizes = [1]\n",
    "\n",
    "#\n",
    "for d_size in d_sizes:\n",
    "    print('============= d_size =============', d_size)\n",
    "    for lamb in lambda_list:\n",
    "        #if lamb==2 or lamb==4: continue\n",
    "        emb_std = lamb\n",
    "        mode_list = [0] # 0,1 모두 돈다\n",
    "        if task2_nextAct:\n",
    "            seq_std_list = [1,2,3]\n",
    "            label_num=2\n",
    "        elif task3_outlier:\n",
    "            seq_std_list = [60]\n",
    "            label_num=2\n",
    "        elif task4_lifetime:\n",
    "            seq_std_list = [100]\n",
    "            label_num=100\n",
    "        elif task5_multiFixtime:\n",
    "            seq_std_list = [100]\n",
    "            label_num=100\n",
    "        else: # task_1\n",
    "            seq_std_list = [5,4,3,2,1]\n",
    "            label_num=2\n",
    "        #\n",
    "        for seq_std in seq_std_list:\n",
    "            if task3_outlier:\n",
    "                all_class = [1 if x>=seq_std else 0 for x in all_total]\n",
    "            else:\n",
    "                all_class = [0 if x<=seq_std else 1 for x in all_time]\n",
    "            c0 = all_class.count(0)\n",
    "            c1 = all_class.count(1)\n",
    "            class_percent = c1/(c0+c1)\n",
    "            print('class 1 비율', class_percent*100)\n",
    "            if auto_balancing:\n",
    "                if class_percent<=0.4 or class_percent>=0.6:\n",
    "                    train_balancing=True\n",
    "                else:\n",
    "                    train_balancing=False\n",
    "            #\n",
    "            m3_runT = []\n",
    "            m5_runT = []\n",
    "            for mode in mode_list: # 0:3-5, 1:4-6\n",
    "                if mode==1: continue\n",
    "                if mode==0:\n",
    "                    doc2vec_rnn = True\n",
    "                    m3_stacking = False\n",
    "                    doc2vec_avg = False\n",
    "                    multi_layer_LSTM = False\n",
    "                elif mode ==1:\n",
    "                    doc2vec_rnn = False \n",
    "                    m3_stacking = False\n",
    "                    doc2vec_avg = True\n",
    "                    multi_layer_LSTM = False\n",
    "                for i in range(6,11):\n",
    "                    totalLength = len(all_data)\n",
    "                    print('Total length: ', totalLength)\n",
    "                    splitLength = int(totalLength / (numCV + 1))\n",
    "                    print('emb_std:',emb_std)\n",
    "                    print('seq_std:', seq_std)\n",
    "                    print('train_balancing', train_balancing)\n",
    "                    # Split cross validation set\n",
    "                    print ('CV',i)\n",
    "                    if test_mode:\n",
    "                        train_data = all_data[:30]#i*splitLength]\n",
    "                        train_history = all_history[:30]#i*splitLength]\n",
    "                        train_3to1 = sum([len(r) for r in train_data])       \n",
    "                        train_time = all_time[:train_3to1]#i*splitLength]\n",
    "                        train_workday = all_workday[:train_3to1]\n",
    "                        train_recentday = all_recentday[:train_3to1]\n",
    "                        train_openday = all_openday[:train_3to1]\n",
    "                        train_activitycnt = all_activitycnt[:train_3to1]\n",
    "                        train_cc = all_cc[:train_3to1]\n",
    "                        train_writer = all_writer[:train_3to1]\n",
    "                        train_bugid = all_bugid[:train_3to1]\n",
    "                        train_total = all_total[:train_3to1]\n",
    "                    else:\n",
    "                        train_data = all_data[:int(i*splitLength*d_size)]\n",
    "                        train_history = all_history[:int(i*splitLength*d_size)]\n",
    "                        train_3to1 = sum([len(r) for r in train_data])       \n",
    "                        train_time = all_time[:train_3to1]#i*splitLength]\n",
    "                        train_workday = all_workday[:train_3to1]\n",
    "                        train_recentday = all_recentday[:train_3to1]\n",
    "                        train_openday = all_openday[:train_3to1]\n",
    "                        train_activitycnt = all_activitycnt[:train_3to1]\n",
    "                        train_cc = all_cc[:train_3to1]\n",
    "                        train_writer = all_writer[:train_3to1]\n",
    "                        train_bugid = all_bugid[:train_3to1]\n",
    "                        train_total = all_total[:train_3to1]\n",
    "                    # ===================================================================== \n",
    "                    updated_train_data = []    \n",
    "                    updated_train_history = []    \n",
    "                    updated_train_time = []\n",
    "                    #updated_train_stream = []\n",
    "                    #updated_train_workday = []\n",
    "                    #updated_train_bugid = []\n",
    "\n",
    "                    j=0\n",
    "                    for bug1, bug2 in zip(train_data, train_history):\n",
    "                        train_data_list = []\n",
    "                        train_history_list = []\n",
    "                        if len(bug1)>=min_activity_len:\n",
    "                            for act1, act2 in zip(bug1, bug2):\n",
    "                                current_train_filter = [word for word in act1 if word in vocabulary]\n",
    "                                his_current_train_filter = [word for word in act2 if word in vocabulary]\n",
    "                                train_data_list.append(current_train_filter)\n",
    "                                train_history_list.append(his_current_train_filter)\n",
    "                                #updated_train_time.append(train_time[j])\n",
    "                                #updated_train_stream.append(train_stream[j])\n",
    "                                #updated_train_workday.append(train_workday[j])\n",
    "                                #updated_train_bugid.append(train_bugid[j])\n",
    "                                j+=1\n",
    "                            updated_train_data.append(train_data_list)\n",
    "                            updated_train_history.append(train_history_list)\n",
    "                        else:\n",
    "                            j+=len(bug1)\n",
    "\n",
    "                    del train_data, train_history, #train_bugid, train_workday\n",
    "                    gc.collect()\n",
    "\n",
    "                    # ===================================================================== \n",
    "                    updated_train_time = [1 if x<=seq_std else 0 for x in train_time]\n",
    "                    curr_split = total_split[data_name[path]][0]\n",
    "                    updated_train_workday = [0 if x<=curr_split[0] else 1 if x<=curr_split[1] else 2 for x in train_workday]\n",
    "                    updated_train_recentday = []\n",
    "                    for x in train_recentday:\n",
    "                        tmp = 0 \n",
    "                        for j,y in enumerate(x):\n",
    "                            tmp+= pow(2,j)*y\n",
    "                        updated_train_recentday.append(tmp) \n",
    "                    curr_split = total_split[data_name[path]][1]\n",
    "                    updated_train_openday = [0 if x<=curr_split[0] else 1 if x<=curr_split[1] else 2 if x<=curr_split[2] else 3 if x<=curr_split[3] else 4 for x in train_openday]\n",
    "                    curr_split = total_split[data_name[path]][2]\n",
    "                    updated_train_activitycnt = [0 if x<=curr_split[0] else 1 if x<=curr_split[1] else 2 if x<=curr_split[2] else 3 if x<=curr_split[3] else 4 for x in train_activitycnt]\n",
    "                    curr_split = total_split[data_name[path]][3]\n",
    "                    updated_train_cc = [0 if x<=curr_split[0] else 1 if x<=curr_split[1] else 2 if x<=curr_split[2] else 3 for x in train_cc]\n",
    "                    updated_train_writer = train_writer\n",
    "                    updated_train_bugid = train_bugid\n",
    "                    updated_train_data_1d = [y for x in updated_train_data for y in x]\n",
    "                    updated_train_history_1d = [y for x in updated_train_history for y in x]\n",
    "                    train_col_size = [len(x) for x in updated_train_data]\n",
    "                    train_n = len(updated_train_data_1d)\n",
    "                    train_df =pd.DataFrame({'x1': updated_train_data_1d, 'x2': updated_train_history_1d, \n",
    "                                            's1': updated_train_workday, 's2':updated_train_recentday, 's3':updated_train_activitycnt,\n",
    "                                            's4':updated_train_cc, 's5':updated_train_writer, 's6':updated_train_openday,\n",
    "                                            'bugid':updated_train_bugid,\n",
    "                                            'y1': train_time, 'y2':updated_train_time})\n",
    "                    #print(train_df[:10])\n",
    "                    del updated_train_time, updated_train_history, updated_train_data, updated_train_data_1d, updated_train_history_1d\n",
    "                    del updated_train_workday, updated_train_recentday, updated_train_activitycnt, updated_train_cc, updated_train_writer, updated_train_bugid\n",
    "                    gc.collect()\n",
    "\n",
    "                    # Task type\n",
    "                    if task2_nextAct:\n",
    "                        train_nextact = []\n",
    "                        q=0\n",
    "                        for col_size in train_col_size:\n",
    "                            for x in range(col_size):\n",
    "                                if x==col_size-1:\n",
    "                                    train_nextact.append(-1)\n",
    "                                else:\n",
    "                                    train_nextact.append(train_time[q+x]-train_time[q+x+1])\n",
    "                            q+=col_size\n",
    "                        train_df['y1'] = train_nextact\n",
    "                        train_df = train_df[train_df.y1!=-1]\n",
    "                        train_n = len(train_df)\n",
    "                        # new train_col_size\n",
    "                        cnt=0\n",
    "                        train_col_size = []\n",
    "                        prev_id = train_df.iloc[0]['bugid']\n",
    "                        for x in train_df.bugid.values:\n",
    "                            if prev_id != x:\n",
    "                                train_col_size.append(cnt)\n",
    "                                cnt = 0\n",
    "                            prev_id = x\n",
    "                            cnt+=1\n",
    "                        train_col_size.append(cnt)\n",
    "                    elif task3_outlier or task4_lifetime:\n",
    "                        train_df['y1'] = train_total\n",
    "                    \n",
    "                    # =============================\n",
    "                    # BALANCE RESAMPLING\n",
    "                    if train_balancing:\n",
    "                        class_count = train_df.y2.value_counts()\n",
    "                        print('\\nClass 0:', class_count[0])\n",
    "                        print('Class 1:', class_count[1])\n",
    "                        df_class_0 = train_df[train_df['y2']==0]\n",
    "                        df_class_1 = train_df[train_df['y2']==1]\n",
    "                        if class_count[0]<class_count[1]:\n",
    "                            under_class_cnt = class_count[0]\n",
    "                            df_class_1 = df_class_1.sample(under_class_cnt)\n",
    "                        else:\n",
    "                            under_class_cnt = class_count[1]\n",
    "                            df_class_0 = df_class_0.sample(under_class_cnt)\n",
    "                        train_df = pd.concat([df_class_0, df_class_1], axis=0)\n",
    "                        train_df = train_df.sort_index()\n",
    "                        train_n = len(train_df)\n",
    "                        print(train_df[:10],'\\n')\n",
    "                        print('\\nRandom under-sampling:')\n",
    "                        print(train_df.y2.value_counts(),'\\n')\n",
    "                        # new train_col_size\n",
    "                        cnt=0\n",
    "                        train_col_size = []\n",
    "                        prev_id = train_df.iloc[0]['bugid']\n",
    "                        for x in train_df.bugid.values:\n",
    "                            if prev_id != x:\n",
    "                                train_col_size.append(cnt)\n",
    "                                cnt = 0\n",
    "                            prev_id = x\n",
    "                            cnt+=1\n",
    "                        train_col_size.append(cnt)\n",
    "\n",
    "                    # ===================================================================== \n",
    "                    X_train_last = np.zeros(shape=[train_n, max_sentence_len, embed_size_word2vec], dtype='float32') # len(updated_train_data) # train_len*2\n",
    "                    X_train_history = np.zeros(shape=[train_n, max_his_len, embed_size_word2vec], dtype='float32') # len(updated_train_history)\n",
    "                    Y_train = np.empty(shape=[train_n,1], dtype='int32') # len(updated_train_time)\n",
    "\n",
    "                    j=0\n",
    "                    for curr_row1, curr_row2 in zip(train_df.x1.values, train_df.x2.values):\n",
    "                        if len(curr_row1)>max_sentence_len:\n",
    "                            start_loc = len(curr_row1) - max_sentence_len\n",
    "                        else: \n",
    "                            start_loc = 0\n",
    "                        sequence_cnt = 0    \n",
    "                        for item1 in curr_row1[start_loc:]:\n",
    "                            if item1 in vocabulary:\n",
    "                                X_train_last[j, sequence_cnt, :] = wordvec_model[item1] \n",
    "                                sequence_cnt = sequence_cnt + 1                \n",
    "                                if sequence_cnt == max_sentence_len-1:\n",
    "                                    break  \n",
    "                        for k in range(sequence_cnt, max_sentence_len):\n",
    "                            X_train_last[j, k, :] = np.zeros((1,embed_size_word2vec))   \n",
    "                        if len(curr_row2)>max_his_len:\n",
    "                            start_loc = len(curr_row2) - max_his_len\n",
    "                        else: \n",
    "                            start_loc = 0\n",
    "                        sequence_cnt = 0\n",
    "                        for item2 in curr_row2[start_loc:]:\n",
    "                            if item2 in vocabulary:\n",
    "                                X_train_history[j, sequence_cnt, :] = wordvec_model[item2] \n",
    "                                sequence_cnt = sequence_cnt + 1                \n",
    "                                if sequence_cnt == max_his_len-1:\n",
    "                                        break \n",
    "                        for k in range(sequence_cnt, max_his_len):\n",
    "                            X_train_history[j, k, :] = np.zeros((1,embed_size_word2vec))\n",
    "                        Y_train[j] = train_df.y1.values[j]\n",
    "                        j+=1\n",
    "                    #y_train = np_utils.to_categorical(Y_train, label_num)\n",
    "\n",
    "                    if doc2vec_avg:\n",
    "                        X_train_doc = np.zeros(shape=[train_n, embed_size_word2vec], dtype='float32')\n",
    "                        X_train_his_doc = np.zeros(shape=[train_n, embed_size_word2vec], dtype='float32')\n",
    "                        for j,words in enumerate(X_train_last):\n",
    "                            cnt=0\n",
    "                            smt = np.asarray([0.0 for p in range(embed_size_word2vec)])\n",
    "                            for word in words:\n",
    "                                if not np.any(word): # All-zero element?\n",
    "                                    break\n",
    "                                smt+=word\n",
    "                                cnt+=1\n",
    "                            if not np.any(smt):\n",
    "                                avg = smt\n",
    "                            else:\n",
    "                                avg = smt/cnt\n",
    "                            X_train_doc[j] = avg\n",
    "                        for j,words in enumerate(X_train_history):\n",
    "                            cnt=0\n",
    "                            smt = np.asarray([0.0 for p in range(embed_size_word2vec)])\n",
    "                            for word in words:\n",
    "                                if not np.any(word): # All-zero element?\n",
    "                                    break\n",
    "                                smt+=word\n",
    "                                cnt+=1\n",
    "                            if not np.any(smt):\n",
    "                                avg = smt\n",
    "                            else:\n",
    "                                avg = smt/cnt\n",
    "                            X_train_his_doc[j] = avg\n",
    "\n",
    "                        X_train_avg = np.concatenate((X_train_doc, X_train_his_doc),axis=1)\n",
    "                        del X_train_last, X_train_history\n",
    "                        gc.collect()\n",
    "\n",
    "                    # Statistic\n",
    "                    X_train_workday = np.asarray(train_df.s1.values, dtype=np.float32)\n",
    "                    class_num = len(total_split[data_name[path]][0])+1\n",
    "                    X_train_workday = np_utils.to_categorical(X_train_workday, class_num)\n",
    "                    X_train_openday = np.asarray(train_df.s6.values, dtype=np.float32)\n",
    "                    class_num = len(total_split[data_name[path]][1])+1\n",
    "                    X_train_openday = np_utils.to_categorical(X_train_openday, class_num)\n",
    "                    X_train_recentday = np.asarray(train_df.s2.values, dtype=np.float32)\n",
    "                    class_num = 8\n",
    "                    X_train_recentday = np_utils.to_categorical(X_train_recentday, class_num)\n",
    "                    X_train_activitycnt = np.asarray(train_df.s3.values, dtype=np.float32)\n",
    "                    class_num = len(total_split[data_name[path]][2])+1\n",
    "                    X_train_activitycnt = np_utils.to_categorical(X_train_activitycnt, class_num)\n",
    "                    X_train_cc = np.asarray(train_df.s4.values, dtype=np.float32)\n",
    "                    class_num = len(total_split[data_name[path]][3])+1\n",
    "                    X_train_cc = np_utils.to_categorical(X_train_cc, class_num)\n",
    "                    X_train_writer = np.array([np.array(x, dtype=np.float32) for x in train_df.s5.values])\n",
    "\n",
    "                    X_train_stat = np.concatenate((X_train_workday, X_train_recentday),axis=1)\n",
    "                    X_train_stat = np.concatenate((X_train_stat, X_train_openday),axis=1)\n",
    "                    X_train_stat = np.concatenate((X_train_stat, X_train_activitycnt),axis=1)\n",
    "                    X_train_stat = np.concatenate((X_train_stat, X_train_cc),axis=1)\n",
    "                    X_train_stat = np.concatenate((X_train_stat, X_train_writer),axis=1)\n",
    "\n",
    "                    # Model\n",
    "                    if doc2vec_rnn:\n",
    "                        h1=256\n",
    "                        h2 = 32\n",
    "                        last_input = Input(shape=(max_sentence_len, embed_size_word2vec), dtype='float32')\n",
    "                        mask_1 = Masking(mask_value=0)(last_input)\n",
    "                        if bidirectional:\n",
    "                            merged_1 = Bidirectional(LSTM(h1, name='merged_1'))(mask_1)\n",
    "                        else:\n",
    "                            forwards_1 = LSTM(h1, name='forwards_1')(mask_1)\n",
    "                            backwards_1 = LSTM(h1, go_backwards=True, name='backwords_1')(mask_1)         \n",
    "                            merged_1 = keras.layers.concatenate([forwards_1, backwards_1], axis=-1)\n",
    "                        after_dp_1= Dropout(0.5, name='after_dp_1')(merged_1)\n",
    "                        tmp_output_1 = Dense(label_num, activation='softmax', name='tmp_output_1')(after_dp_1)\n",
    "\n",
    "                        history_input = Input(shape=(max_his_len, embed_size_word2vec), dtype='float32')\n",
    "                        mask_2 = Masking(mask_value=0)(history_input)\n",
    "                        if bidirectional:\n",
    "                            merged_2 = Bidirectional(LSTM(h2, name='merged_2'))(mask_2)\n",
    "                        else:\n",
    "                            forwards_2 = LSTM(h2, name='forwards_2')(mask_2)\n",
    "                            backwards_2 = LSTM(h2, go_backwards=True, name='backwards_2')(mask_2)\n",
    "                            merged_2 = keras.layers.concatenate([forwards_2, backwards_2], axis=-1)\n",
    "                        after_dp_2 = Dropout(0.5, name='after_dp_2')(merged_2)\n",
    "                        tmp_output_2 = Dense(label_num, activation='softmax', name='tmp_output_2')(after_dp_2)\n",
    "\n",
    "                        # stat\n",
    "                        stat_input = Input(shape=(len(X_train_stat[0]),), dtype='float32')\n",
    "\n",
    "                        middle_merge = keras.layers.concatenate([after_dp_1, after_dp_2, stat_input], axis=-1)\n",
    "                        middle_dense = Dense(380, name='middle_dense_1')(middle_merge) \n",
    "                        middle_dense = LeakyReLU(alpha=0.3)(middle_dense)\n",
    "                        middle_dense = Dense(450, name='middle_dense_2')(middle_dense) \n",
    "                        middle_dense = LeakyReLU(alpha=0.2)(middle_dense)\n",
    "                        middle_dense = Dense(200, name='middle_dense_3', activation='tanh')(middle_dense) \n",
    "                        #middle_dense = LeakyReLU(alpha=0.5)(middle_dense)\n",
    "                        #last_dense = Dense(100, name='middle_dense_4')(middle_dense) \n",
    "                        #last_dense = LeakyReLU(alpha=0.1)(last_dense)\n",
    "                        output = Dense(label_num, activation='softmax', name='output')(middle_dense)\n",
    "                        if m3_stacking:\n",
    "                            user_model = Model(input=last_input, output = tmp_output_1)\n",
    "                            sys_model = Model(input=history_input, output=tmp_output_2)\n",
    "                        embedding_size = 200\n",
    "                        m3 = Model(input=[last_input, history_input, stat_input], output=output)    \n",
    "\n",
    "                    elif doc2vec_avg:\n",
    "                        docAvg_input = Input(shape=(len(X_train_avg[0]),), dtype='float32')\n",
    "                        stat_input = Input(shape=(len(X_train_stat[0]),), dtype='float32')\n",
    "                        concat_input = keras.layers.concatenate([docAvg_input, stat_input], axis=-1)\n",
    "                        middle_dense = Dense(230, name='middle_dense_1')(concat_input) \n",
    "                        middle_dense = LeakyReLU(alpha=0.3)(middle_dense)\n",
    "                        middle_dense = Dense(300, name='middle_dense_2')(middle_dense) \n",
    "                        middle_dense = LeakyReLU(alpha=0.2)(middle_dense)\n",
    "                        middle_dense = Dense(180, name='middle_dense_3')(middle_dense) \n",
    "                        middle_dense = LeakyReLU(alpha=0.5)(middle_dense)\n",
    "                        last_dense = Dense(100, name='middle_dense_4')(middle_dense) \n",
    "                        last_dense = LeakyReLU(alpha=0.1)(last_dense)\n",
    "                        output = Dense(label_num, activation='softmax', name='output')(last_dense)\n",
    "\n",
    "                        embedding_size = 180\n",
    "                        m3 = Model(input=[docAvg_input, stat_input], output=output)    \n",
    "\n",
    "                    adam = Adam(lr=0.0002, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "                    m3.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "                    # TRAIN MODEL\n",
    "                    es = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto')\n",
    "\n",
    "                    print('\\n\\n******************* M3-RNN *******************')  \n",
    "                    if emb_load:\n",
    "                        pass\n",
    "                    else:\n",
    "                        X_train_last_sp, X_valid_last, X_train_history_sp, X_valid_history, X_train_stat_sp, X_valid_stat, y_train_sp, y_valid = train_test_split(X_train_last, X_train_history, X_train_stat, y_train, test_size=0.15, shuffle= True)\n",
    "                        m3.summary()\n",
    "                        start = time.time()\n",
    "                        hist = m3.fit([X_train_last_sp, X_train_history_sp, X_train_stat_sp], y_train_sp, batch_size=batch_size, \n",
    "                                         validation_data = ([X_valid_last, X_valid_history, X_valid_stat], y_valid), epochs=20, callbacks=[es])\n",
    "                        end = time.time()\n",
    "                        m3_runT.append(int(end-start))\n",
    "                        print(\" ********* emb%d-M3 Learning time: %dsec ********* \" %(emb_std,int(end-start)))\n",
    "                        del X_train_last_sp, X_train_history_sp, X_train_stat_sp, y_train_sp\n",
    "                        del X_valid_last, X_valid_history, X_valid_stat, y_valid\n",
    "                        gc.collect()\n",
    "                        if not save_off:\n",
    "                            # Save model\n",
    "                            model_json = m3.to_json()\n",
    "                            model_name = data_name[path]+\"_M3_limit100_class\"+str(emb_std)+\"_cv\"+str(i)+\".json\"\n",
    "                            weight_name = data_name[path]+\"_M3_limit100_class\"+str(emb_std)+\"_cv\"+str(i)+\".h5\"\n",
    "                            with open(model_name,\"w\") as json_file :\n",
    "                                json_file.write(model_json)\n",
    "                                m3.save_weights(weight_name)\n",
    "                            print(\"Saved model to disk\\n\\n\\n\")\n",
    "\n",
    "                    print('\\n\\n******************* M5- seqence RNN *******************')\n",
    "                    # load seq-embedding weights\n",
    "                    model_1 = Model(input=[last_input, history_input, stat_input], output=middle_dense) \n",
    "                    weight_name = data_name[path]+\"_M3_tanh_limit100_class\"+str(emb_std)+\"_cv\"+str(i)+\".h5\"\n",
    "                    model_1.load_weights(weight_name, by_name=True)                 \n",
    "\n",
    "                    embedding_train_output = model_1.predict([X_train_last, X_train_history, X_train_stat])\n",
    "                    del X_train_last, X_train_history, X_train_stat\n",
    "                    gc.collect()\n",
    "\n",
    "                    X_train_activity = np.zeros(shape=[len(train_col_size), max_activity_len, embedding_size], dtype='float32') \n",
    "                    y_train_activity = np.full((len(train_col_size), max_activity_len, label_num), -1, dtype='int32') \n",
    "                    act_idx = 0 # 200d_activity_output row\n",
    "\n",
    "                    for j, col_size in enumerate(train_col_size):\n",
    "                        for p in range(col_size):\n",
    "                            X_train_activity[j,p,:] = embedding_train_output[act_idx+p]\n",
    "                            if task3_outlier:\n",
    "                                if train_df.y1.values[act_idx+p]>=seq_std:\n",
    "                                    y_train_activity[j,p,0] = 0\n",
    "                                    y_train_activity[j,p,1] = 1\n",
    "                                else:\n",
    "                                    y_train_activity[j,p,0] = 1\n",
    "                                    y_train_activity[j,p,1] = 0\n",
    "                            elif task4_lifetime or task5_multiFixtime:\n",
    "                                y_train_activity[j,p,:] = np.zeros(label_num, dtype='int32')\n",
    "                                y_train_activity[j,p,train_df.y1.values[act_idx+p]] = 1\n",
    "                            else: # Task1\n",
    "                                if train_df.y1.values[act_idx+p]<=seq_std:\n",
    "                                    y_train_activity[j,p,0] = 0\n",
    "                                    y_train_activity[j,p,1] = 1\n",
    "                                else:\n",
    "                                    y_train_activity[j,p,0] = 1\n",
    "                                    y_train_activity[j,p,1] = 0\n",
    "                        act_idx += col_size\n",
    "                    del embedding_train_output \n",
    "                    gc.collect()\n",
    "\n",
    "                    # construct seq-emb model\n",
    "                    if ResLSTM:\n",
    "                        data_input = Input(shape=(max_activity_len, embedding_size), dtype='float32')\n",
    "                        output = make_residual_lstm_layers(data_input, rnn_width=embedding_size, rnn_depth=8, rnn_dropout=0.2)\n",
    "                        #task_output = TimeDistributed(Dense(label_num, activation='softmax'))(output) \n",
    "                        seq_emb = Model(input=data_input, output=output)\n",
    "                    else:\n",
    "                        activity_input = Input(shape=(max_activity_len, embedding_size), dtype='float32')\n",
    "                        mask = Masking(mask_value=0)(activity_input)\n",
    "                        forwards_1 = LSTM(256, name='forwards_1', return_sequences=True)(mask)\n",
    "                        forwards_1 = Dropout(0.5)(forwards_1)\n",
    "                        #forwards = LSTM(128, return_sequences=True)(forwards)\n",
    "                        #forwards = Dropout(0.3)(forwards)\n",
    "                        emb_output = TimeDistributed(Dense(label_num, activation='relu'))(forwards_1)\n",
    "                        forwards_2 = LSTM(256, name='forwards_2', return_sequences=True)(emb_output)\n",
    "                        forwards_3 = LSTM(128, name='forwards_3', return_sequences=True)(forwards_2)\n",
    "                        output = TimeDistributed(Dense(2, activation='softmax'))(forwards_3)\n",
    "                        seq_emb = Model(input=activity_input, output=output)  \n",
    "\n",
    "                    adam = Adam(lr=0.0002, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "                    #seq_emb.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "                    #seq_emb.summary()\n",
    "\n",
    "                    # load seq-embedding model\n",
    "                    model_json = data_name[path]+\"_newM5_limit100_emb\"+str(lamb)+\"_seq\"+str(lamb)+\"_cv\"+str(i)+\".json\"\n",
    "                    model_h5 = data_name[path]+\"_newM5_limit100_emb\"+str(lamb)+\"_seq\"+str(lamb)+\"_cv\"+str(i)+\".h5\"\n",
    "                    json_file = open(model_json, \"r\")\n",
    "                    loaded_model_json=json_file.read()\n",
    "                    json_file.close()\n",
    "                    loaded_seq_emb=model_from_json(loaded_model_json)\n",
    "                    loaded_seq_emb.load_weights(model_h5)\n",
    "\n",
    "                    # get wieghts\n",
    "                    weights_list = loaded_seq_emb.get_weights()\n",
    "                    j=0\n",
    "                    for layer1, layer2 in zip(loaded_seq_emb.layers, seq_emb.layers):\n",
    "                        seq_emb.layers[j].set_weights(layer1.get_weights())\n",
    "                        j+=1\n",
    "\n",
    "                    # construct task model\n",
    "                    if task_mlp:\n",
    "                        activity_input = Input(shape=(max_activity_len, embedding_size), dtype='float32')\n",
    "                        mask = Masking(mask_value=0)(activity_input)\n",
    "                        mid_dense = TimeDistributed(Dense(120, name='mid_dense_1'))(mask) \n",
    "                        mid_dense = TimeDistributed(LeakyReLU(alpha=0.2))(mid_dense)\n",
    "                        mid_dense = TimeDistributed(Dense(230, name='mid_dense_2'))(mid_dense) \n",
    "                        mid_dense = TimeDistributed(LeakyReLU(alpha=0.35))(mid_dense)\n",
    "                        mid_dense = TimeDistributed(Dense(100, name='mid_dense_3'))(mid_dense) \n",
    "                        mid_dense = TimeDistributed(LeakyReLU(alpha=0.1))(mid_dense)\n",
    "                        output = TimeDistributed(Dense(label_num, activation='softmax'))(mid_dense)\n",
    "                    else:\n",
    "                        activity_input = Input(shape=(max_activity_len, embedding_size), dtype='float32')\n",
    "                        mask = Masking(mask_value=0)(activity_input)\n",
    "                        forwards = LSTM(256, name='forwards_1', return_sequences=True)(mask)\n",
    "                        forwards = Dropout(0.4)(forwards)\n",
    "                        #forwards = LSTM(128, name='forwards_2', return_sequences=True)(forwards)\n",
    "                        #forwards = Dropout(0.3)(forwards)\n",
    "                        output = TimeDistributed(Dense(label_num, activation='softmax'))(forwards)\n",
    "\n",
    "                    model = Model(input=activity_input, output=output)  \n",
    "                    if label_num==2:\n",
    "                        model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "                    else:\n",
    "                        model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=[metrics.categorical_accuracy])\n",
    "                    model.summary()\n",
    "\n",
    "                    # get seq_emb output\n",
    "                    seq_emb_output = seq_emb.predict(X_train_activity)\n",
    "                    X_train_emb = np.zeros(shape=[len(train_col_size), max_activity_len, embedding_size], dtype='float32') \n",
    "\n",
    "                    for j, col_size in enumerate(train_col_size):\n",
    "                        for p in range(col_size):\n",
    "                            X_train_emb[j,p,:] = seq_emb_output[j,p,:]\n",
    "                    del seq_emb_output \n",
    "                    gc.collect()\n",
    "\n",
    "                    # train model\n",
    "                    es = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto')\n",
    "                    X_train_emb, X_valid_emb, y_train_activity, y_valid_activity = train_test_split(X_train_emb, y_train_activity, test_size=0.15, shuffle= True)\n",
    "                    start = time.time()\n",
    "                    hist = model.fit(X_train_emb, y_train_activity, batch_size=batch_size, \n",
    "                                     validation_data = (X_valid_emb, y_valid_activity), epochs=20, callbacks=[es])\n",
    "                    end = time.time()\n",
    "                    m5_runT.append(end-start)\n",
    "                    print(\" ********* seq%d-M5 Learning time: %dsec ********* \" %(seq_std,int(end-start)))\n",
    "                    train_result = hist.history\n",
    "                    print('\\nTrain_result\\n')\n",
    "                    print(train_result)\n",
    "                    del X_train_emb, X_valid_emb, y_train_activity, y_valid_activity\n",
    "                    gc.collect()\n",
    "\n",
    "                    if not save_off:\n",
    "                        # Save model\n",
    "                        model_json = model.to_json()\n",
    "                        model_name = data_name[path]+\"_newM5_limit100_task1_day\"+str(seq_std)+\"_cv\"+str(i)+\".json\"\n",
    "                        weight_name = data_name[path]+\"_newM5_limit100_task1_day\"+str(seq_std)+\"_cv\"+str(i)+\".h5\"\n",
    "                        with open(model_name,\"w\") as json_file :\n",
    "                            json_file.write(model_json)\n",
    "                            model.save_weights(weight_name)\n",
    "                        print(\"Saved model to disk\\n\\n\\n\")  \n",
    "\n",
    "                    #========================================================================================\n",
    "                    # TEST DATA\n",
    "                    #========================================================================================\n",
    "                    if test_mode:\n",
    "                        test_data = all_data[30:50]#i*splitLength:(i+1)*splitLength] \n",
    "                        test_history = all_history[30:50]#i*splitLength:(i+1)*splitLength]\n",
    "                        test_3to1 = sum([len(r) for r in test_data])\n",
    "                        test_time = all_time[train_3to1:train_3to1+test_3to1]#i*splitLength:(i+1)*splitLength]\n",
    "                        #test_stream = all_stream[train_3to1 : train_3to1+test_3to1]\n",
    "                        test_workday = all_workday[train_3to1:train_3to1+test_3to1]\n",
    "                        test_recentday = all_recentday[train_3to1:train_3to1+test_3to1]\n",
    "                        test_openday = all_openday[train_3to1:train_3to1+test_3to1]\n",
    "                        test_activitycnt = all_activitycnt[train_3to1:train_3to1+test_3to1]\n",
    "                        test_cc = all_cc[train_3to1:train_3to1+test_3to1]\n",
    "                        test_writer = all_writer[train_3to1:train_3to1+test_3to1]\n",
    "                        test_bugid = all_bugid[train_3to1:train_3to1+test_3to1]\n",
    "                        test_total = all_total[train_3to1:train_3to1+test_3to1]\n",
    "                    else:\n",
    "                        test_data = all_data[i*splitLength:(i+1)*splitLength]\n",
    "                        test_history = all_history[i*splitLength:(i+1)*splitLength]\n",
    "                        test_3to1 = sum([len(r) for r in test_data])       \n",
    "                        test_time = all_time[train_3to1 : train_3to1+test_3to1]#i*splitLength]\n",
    "                        #test_stream = all_stream[train_3to1:train_3to1+test_3to1]\n",
    "                        test_workday = all_workday[train_3to1:train_3to1+test_3to1]\n",
    "                        test_recentday = all_recentday[train_3to1:train_3to1+test_3to1]\n",
    "                        test_openday = all_openday[train_3to1:train_3to1+test_3to1]\n",
    "                        test_activitycnt = all_activitycnt[train_3to1:train_3to1+test_3to1]\n",
    "                        test_cc = all_cc[train_3to1:train_3to1+test_3to1]\n",
    "                        test_writer = all_writer[train_3to1:train_3to1+test_3to1]\n",
    "                        test_bugid = all_bugid[train_3to1:train_3to1+test_3to1]\n",
    "                        test_total = all_total[train_3to1:train_3to1+test_3to1]\n",
    "                    # ===================================================================== \n",
    "                    updated_test_data = []    \n",
    "                    updated_test_history = []    \n",
    "                    updated_test_time = []\n",
    "                    #updated_test_stream = []\n",
    "                    #updated_test_workday = []\n",
    "                    #updated_test_bugid = []\n",
    "\n",
    "                    j=0\n",
    "                    for bug1, bug2 in zip(test_data, test_history):\n",
    "                        test_data_list = []\n",
    "                        test_history_list = []\n",
    "                        if len(bug1)>=min_activity_len:\n",
    "                            for act1, act2 in zip(bug1, bug2):\n",
    "                                current_test_filter = [word for word in act1 if word in vocabulary]\n",
    "                                his_current_test_filter = [word for word in act2 if word in vocabulary]\n",
    "                                test_data_list.append(current_test_filter)\n",
    "                                test_history_list.append(his_current_test_filter)\n",
    "                                #updated_test_time.append(test_time[j])\n",
    "                                #updated_test_stream.append(test_stream[j])\n",
    "                                #updated_test_workday.append(test_workday[j])\n",
    "                                #updated_test_bugid.append(test_bugid[j])\n",
    "                                j+=1\n",
    "                            updated_test_data.append(test_data_list)\n",
    "                            updated_test_history.append(test_history_list)\n",
    "                        else:\n",
    "                            j+=len(bug1)\n",
    "\n",
    "                    del test_data,  test_history, #test_bugid, test_workday, test_time\n",
    "                    gc.collect()\n",
    "\n",
    "                    # ===================================================================== \n",
    "\n",
    "                    #updated_test_time = [0 if x<=class_std else 1 for x in updated_test_time]\n",
    "\n",
    "                    curr_split = total_split[data_name[path]][0]\n",
    "                    updated_test_workday = [0 if x<=curr_split[0] else 1 if x<=curr_split[1] else 2 for x in test_workday]\n",
    "                    updated_test_recentday = []\n",
    "                    for x in test_recentday:\n",
    "                        tmp = 0 \n",
    "                        for j,y in enumerate(x):\n",
    "                            tmp+= pow(2,j)*y\n",
    "                        updated_test_recentday.append(tmp) \n",
    "                    curr_split = total_split[data_name[path]][1]\n",
    "                    updated_test_openday = [0 if x<=curr_split[0] else 1 if x<=curr_split[1] else 2 if x<=curr_split[2] else 3 if x<=curr_split[3] else 4 for x in test_openday]\n",
    "                    curr_split = total_split[data_name[path]][2]\n",
    "                    updated_test_activitycnt = [0 if x<=curr_split[0] else 1 if x<=curr_split[1] else 2 if x<=curr_split[2] else 3 if x<=curr_split[3] else 4 for x in test_activitycnt]\n",
    "                    curr_split = total_split[data_name[path]][3]\n",
    "                    updated_test_cc = [0 if x<=curr_split[0] else 1 if x<=curr_split[1] else 2 if x<=curr_split[2] else 3 for x in test_cc]\n",
    "                    updated_test_writer = test_writer\n",
    "                    updated_test_bugid = test_bugid\n",
    "                    \n",
    "                    updated_test_data_1d = [y for x in updated_test_data for y in x]\n",
    "                    updated_test_history_1d = [y for x in updated_test_history for y in x]\n",
    "                    test_col_size = [len(x) for x in updated_test_data]\n",
    "                    test_n = len(updated_test_data_1d)\n",
    "\n",
    "                    test_df =pd.DataFrame({'x1': updated_test_data_1d, 'x2': updated_test_history_1d, \n",
    "                                            's1': updated_test_workday, 's2':updated_test_recentday, 's3':updated_test_activitycnt,\n",
    "                                            's4':updated_test_cc, 's5':updated_test_writer, 's6':updated_test_openday,\n",
    "                                            'bugid':updated_test_bugid,\n",
    "                                            'y1': test_time})\n",
    "                    del updated_test_data, updated_test_history, #test_workday, test_recentday,test_activitycnt\n",
    "                    gc.collect()\n",
    "\n",
    "                    # Task type\n",
    "                    if task2_nextAct:\n",
    "                        test_nextact = []\n",
    "                        q=0\n",
    "                        for col_size in test_col_size:\n",
    "                            for x in range(col_size):\n",
    "                                if x==col_size-1:\n",
    "                                    test_nextact.append(-1)\n",
    "                                else:\n",
    "                                    test_nextact.append(test_time[q+x]-test_time[q+x+1])\n",
    "                            q+=col_size\n",
    "                        test_df['y1'] = test_nextact\n",
    "                        test_df = test_df[test_df.y1!=-1]\n",
    "                        test_n = len(test_df)\n",
    "                        # new test_col_size\n",
    "                        cnt=0\n",
    "                        test_col_size = []\n",
    "                        prev_id = test_df.iloc[0]['bugid']\n",
    "                        for x in test_df.bugid.values:\n",
    "                            if prev_id != x:\n",
    "                                test_col_size.append(cnt)\n",
    "                                cnt = 0\n",
    "                            prev_id = x\n",
    "                            cnt+=1\n",
    "                        test_col_size.append(cnt)\n",
    "                    elif task3_outlier or task4_lifetime:\n",
    "                        test_df['y1'] = test_total\n",
    "\n",
    "                    # ===================================================================== \n",
    "                    X_test_last = np.zeros(shape=[test_n, max_sentence_len, embed_size_word2vec], dtype='float32') # len(updated_test_data) # test_len*2\n",
    "                    X_test_history = np.zeros(shape=[test_n, max_his_len, embed_size_word2vec], dtype='float32') # len(updated_test_history)\n",
    "                    #X_test_stream = np.empty(shape=[test_n, limit_day], dtype='float32')\n",
    "                    #X_test_workday = np.empty(shape=[test_n, max_workday], dtype='float32')\n",
    "                    Y_test = np.empty(shape=[test_n,1], dtype='int32') # len(updated_test_time)\n",
    "\n",
    "                    j=0\n",
    "                    for curr_row1, curr_row2 in zip(test_df.x1.values, test_df.x2.values):\n",
    "                        if len(curr_row1)>max_sentence_len:\n",
    "                            start_loc = len(curr_row1) - max_sentence_len\n",
    "                        else: \n",
    "                            start_loc = 0\n",
    "                        sequence_cnt = 0    \n",
    "                        for item1 in curr_row1[start_loc:]:\n",
    "                            if item1 in vocabulary:\n",
    "                                X_test_last[j, sequence_cnt, :] = wordvec_model[item1] \n",
    "                                sequence_cnt = sequence_cnt + 1                \n",
    "                                if sequence_cnt == max_sentence_len-1:\n",
    "                                    break  \n",
    "                        for k in range(sequence_cnt, max_sentence_len):\n",
    "                            X_test_last[j, k, :] = np.zeros((1,embed_size_word2vec))   \n",
    "                        if len(curr_row2)>max_his_len:\n",
    "                            start_loc = len(curr_row2) - max_his_len\n",
    "                        else: \n",
    "                            start_loc = 0\n",
    "                        sequence_cnt = 0\n",
    "                        for item2 in curr_row2[start_loc:]:\n",
    "                            if item2 in vocabulary:\n",
    "                                X_test_history[j, sequence_cnt, :] = wordvec_model[item2] \n",
    "                                sequence_cnt = sequence_cnt + 1                \n",
    "                                if sequence_cnt == max_his_len-1:\n",
    "                                        break \n",
    "                        for k in range(sequence_cnt, max_his_len):\n",
    "                            X_test_history[j, k, :] = np.zeros((1,embed_size_word2vec))\n",
    "                        if test_df.y1.values[j]<=lamb:\n",
    "                            Y_test[j,0] = 1\n",
    "                        else:\n",
    "                            Y_test[j,0] = 0\n",
    "                        j+=1\n",
    "\n",
    "                    # Statistic\n",
    "                    X_test_workday = np.asarray(test_df.s1.values, dtype=np.float32)\n",
    "                    class_num = len(total_split[data_name[path]][0])+1\n",
    "                    X_test_workday = np_utils.to_categorical(X_test_workday, class_num)\n",
    "                    X_test_openday = np.asarray(test_df.s6.values, dtype=np.float32)\n",
    "                    class_num = len(total_split[data_name[path]][1])+1\n",
    "                    X_test_openday = np_utils.to_categorical(X_test_openday, class_num)\n",
    "                    X_test_recentday = np.asarray(test_df.s2.values, dtype=np.float32)\n",
    "                    class_num = 8\n",
    "                    X_test_recentday = np_utils.to_categorical(X_test_recentday, class_num)\n",
    "                    X_test_activitycnt = np.asarray(test_df.s3.values, dtype=np.float32)\n",
    "                    class_num = len(total_split[data_name[path]][2])+1\n",
    "                    X_test_activitycnt = np_utils.to_categorical(X_test_activitycnt, class_num)\n",
    "                    X_test_cc = np.asarray(test_df.s4.values, dtype=np.float32)\n",
    "                    class_num = len(total_split[data_name[path]][3])+1\n",
    "                    X_test_cc = np_utils.to_categorical(X_test_cc, class_num)\n",
    "                    X_test_writer = np.array([np.array(x, dtype=np.float32) for x in test_df.s5.values])\n",
    "\n",
    "                    X_test_stat = np.concatenate((X_test_workday, X_test_recentday),axis=1)\n",
    "                    X_test_stat = np.concatenate((X_test_stat, X_test_openday),axis=1)\n",
    "                    X_test_stat = np.concatenate((X_test_stat, X_test_activitycnt),axis=1)\n",
    "                    X_test_stat = np.concatenate((X_test_stat, X_test_cc),axis=1)\n",
    "                    X_test_stat = np.concatenate((X_test_stat, X_test_writer),axis=1)\n",
    "\n",
    "                    # ===================================================================== \n",
    "                    embedding_test_output = model_1.predict([X_test_last, X_test_history, X_test_stat])\n",
    "                    del model_1\n",
    "                    X_test_activity = np.zeros(shape=[len(test_col_size), max_activity_len, embedding_size], dtype='float32') \n",
    "                    y_test_activity = np.full((len(test_col_size), max_activity_len, 1), -1, dtype='int32') \n",
    "                    act_idx = 0 # 200d_activity_output row\n",
    "                    for j, col_size in enumerate(test_col_size):\n",
    "                        for p in range(col_size):\n",
    "                            X_test_activity[j,p,:] = embedding_test_output[act_idx+p]\n",
    "                            if task3_outlier:\n",
    "                                if test_df.y1.values[act_idx+p]>=seq_std:\n",
    "                                    y_test_activity[j,p,:] = 1\n",
    "                                else:\n",
    "                                    y_test_activity[j,p,:] = 0\n",
    "                            elif task4_lifetime or task5_multiFixtime:\n",
    "                                y_test_activity[j,p,:] = test_df.y1.values[act_idx+p]\n",
    "                            else:\n",
    "                                if test_df.y1.values[act_idx+p]<=seq_std:\n",
    "                                    y_test_activity[j,p,:] = 1\n",
    "                                else:\n",
    "                                    y_test_activity[j,p,:] = 0\n",
    "                        act_idx += col_size\n",
    "\n",
    "                    # \n",
    "                    seq_emb_output = seq_emb.predict(X_test_activity)\n",
    "                    X_test_emb = np.zeros(shape=[len(test_col_size), max_activity_len, embedding_size], dtype='float32') \n",
    "                    act_idx = 0 # 200d_activity_output row\n",
    "\n",
    "                    for j, col_size in enumerate(test_col_size):\n",
    "                        for p in range(col_size):\n",
    "                            X_test_emb[j,p,:] = seq_emb_output[j,p,:]\n",
    "                        act_idx += col_size\n",
    "                    del seq_emb_output \n",
    "                    gc.collect()\n",
    "\n",
    "                    X_test_activity = X_test_emb\n",
    "                    '''\n",
    "                    #========================================================================================\n",
    "                    # M3 PREDICT & ACCURACY \n",
    "                    #========================================================================================\n",
    "                    if mode==0:\n",
    "                        print('\\n\\n******************* M3 - Embedding RNN *******************') \n",
    "                    elif mode==1:\n",
    "                        print('\\n\\n******************* M4 - Embedding RNN *******************') \n",
    "                    if doc2vec_rnn:\n",
    "                        predict = m3.predict([X_test_last, X_test_history, X_test_stat])  \n",
    "                        del X_test_last, X_test_history, X_test_stat\n",
    "                    elif doc2vec_avg:\n",
    "                        predict = m3.predict([X_test_avg, X_test_stat]) \n",
    "                        del X_test_avg, X_test_stat\n",
    "                    predictY = np.argmax(predict, axis=1)\n",
    "                    corrects = np.nonzero(predictY.reshape((-1,1)) == Y_test) #.reshape((-1,))\n",
    "                    accu = len(corrects[0])/len(Y_test)\n",
    "                    print(\"Total test accuracy : %.2f\" % (accu*100))\n",
    "                    print('\\nConfusion Matrix')\n",
    "                    cm = confusion_matrix(Y_test, predictY)\n",
    "                    print(cm)\n",
    "                    total = sum(cm[0])+sum(cm[1])\n",
    "                    #print('Predict 0: %.2f' % ((cm[0,0]+cm[1,0])/total*100))\n",
    "                    #print('Predict 1: %.2f' % ((cm[0,1]+cm[1,1])/total*100))\n",
    "                    f1 = (f1_score(Y_test, predictY, average=\"micro\"))\n",
    "                    prec= (precision_score(Y_test, predictY, average=\"micro\"))\n",
    "                    recall = (recall_score(Y_test, predictY, average=\"micro\"))\n",
    "                    print('\\nf1_score: %.2f' % (f1*100))\n",
    "                    print('precision_score: %.2f'% (prec*100)) # class 0 accuracy\n",
    "                    print('recall_score: %.2f' % (recall*100)) # class 1 accuracy\n",
    "                    print('\\n%.2f %.2f %.2f %.2f\\n' %(prec*100, recall*100, f1*100, accu*100))\n",
    "                    print()\n",
    "                    del m3\n",
    "                    gc.collect()\n",
    "                    '''\n",
    "                    #========================================================================================\n",
    "                    # PREDICT & ACCURACY\n",
    "                    #========================================================================================\n",
    "                    if task4_lifetime or task5_multiFixtime:          \n",
    "                        y_test_activity = y_test_activity.reshape((-1,))\n",
    "                        padding_idx = np.where(y_test_activity==-1)\n",
    "                        y_test_activity = np.delete(y_test_activity, padding_idx)\n",
    "                        y_test_activity_topk = np_utils.to_categorical(y_test_activity, label_num)\n",
    "                        \n",
    "                        predict = model.predict(X_test_activity)\n",
    "                        predictY = np.argmax(predict, axis=2)\n",
    "                        predict = predict.reshape((-1,seq_std))\n",
    "                        predict = np.delete(predict, padding_idx, 0)\n",
    "                       \n",
    "                        predictY = predictY.reshape((-1,))\n",
    "                        predictY = np.delete(predictY, padding_idx) \n",
    "                        \n",
    "                        print()\n",
    "                        for k_ in [1,5,10,50]:\n",
    "                            r = K.eval(metrics.top_k_categorical_accuracy(y_test_activity_topk, predict, k=k_))\n",
    "                            print('Top',k_,'Accuracy: %.2f' % (r*100))\n",
    "                        print('\\nConfusion Matrix')\n",
    "                        cm = confusion_matrix(y_test_activity, predictY)\n",
    "                        print(cm)\n",
    "                        print('\\nf1_score: %.2f' % (f1_score(y_test_activity, predictY, average=\"macro\")*100))\n",
    "                        print('precision_score: %.2f'% (precision_score(y_test_activity, predictY, average=\"macro\")*100)) # class 0 accuracy\n",
    "                        print('recall_score: %.2f' % (recall_score(y_test_activity, predictY, average=\"macro\")*100)) # class 1 accuracy\n",
    "                        print()\n",
    "                    else:\n",
    "                        print('\\n\\n******************* M5 -sequence RNN *******************')  \n",
    "                        y_test_activity = y_test_activity.reshape((-1,))\n",
    "                        padding_idx = np.where(y_test_activity==-1)\n",
    "                        y_test_activity = np.delete(y_test_activity, padding_idx)\n",
    "                        print('len(y_test_activity)', len(y_test_activity))\n",
    "                        predict = model.predict(X_test_activity)\n",
    "                        predictY = np.argmax(predict, axis=2)\n",
    "                        print('predictY',predictY[:30])\n",
    "                        predictY = predictY.reshape((-1,))\n",
    "                        predictY = np.delete(predictY, padding_idx)\n",
    "                        print('len(predictY)', len(predictY))\n",
    "                        corrects = np.nonzero(predictY == y_test_activity) #.reshape((-1,))\n",
    "                        accu = len(corrects[0])/len(y_test_activity)\n",
    "                        print(\"Total test accuracy : %.2f\" % (accu*100))\n",
    "                        print('\\nConfusion Matrix')\n",
    "                        cm = confusion_matrix(y_test_activity, predictY)\n",
    "                        print(cm)\n",
    "                        f1 = f1_score(y_test_activity, predictY, average=\"binary\")\n",
    "                        prec = precision_score(y_test_activity, predictY, average=\"binary\")\n",
    "                        recall = recall_score(y_test_activity, predictY, average=\"binary\")\n",
    "                        print('\\nf1_score: %.2f' % (f1*100))\n",
    "                        print('precision_score: %.2f'% (prec*100)) # class 0 accuracy\n",
    "                        print('recall_score: %.2f' % (recall*100)) # class 1 accuracy\n",
    "                        total = sum(cm[0])+sum(cm[1])\n",
    "                        print('Predict 0: %.2f' % ((cm[0,0]+cm[1,0])/total*100))\n",
    "                        print('Predict 1: %.2f' % ((cm[0,1]+cm[1,1])/total*100))\n",
    "                        print('\\n%.2f %.2f %.2f %.2f\\n' %(prec*100, recall*100, f1*100, accu*100))\n",
    "                        print()\n",
    "                    del model\n",
    "\n",
    "            #print('\\n******************',emb_std, 'M3_runT, average :',m3_runT, sum(m3_runT)/len(m3_runT),'******************')\n",
    "            print('******************',seq_std, 'M5_runT, average :', m5_runT, sum(m5_runT)/len(m5_runT),'******************\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepTriage",
   "language": "python",
   "name": "rtdb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
